---
output:
  pdf_document: default
  word_document: default
  html_document: 
    
    df_print: paged
---

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
library(knitr)
library("FactoMineR")
library("factoextra")
library("corrplot")
```

# Chapitre 3 : Analyse en Composantes Principales

## Excercice 23

L'objectif va être de retrouvé les données trouvée en cours sur un jeu de données. Les informations présente dans le cours sont sur ces données : La matrice de corrélation, le vecteur propre, les valeurs propres, ainsi que les coordonées pour les variables et individus. 

```{r message=FALSE,echo=FALSE}
Z1 = c(1.00 ,2.00, 3.00 ,4.00, 9.00)
Z2 = c(5.00 ,10.00 ,8.00 ,8.00 ,12.00)
Z =data.frame(Z1,Z2)
kable(Z,caption = "Données")  #1
```

Le tableau 1 nous montre les données utilisée, il y a 2 variables, Z1 et Z2, pour 5 individus.

```{r message=FALSE,echo=FALSE}
X1 = round((Z1 - mean(Z1)) / 2.79 , 3) #sd(Z1)
X2 = round((Z2 - mean(Z2)) / 2.33 , 3) #sd(Z2)
X =data.frame(X1,X2)
kable(X, caption = "Données centrée réduite") #2
```

Pour étudier ces donnée il faut d'abord les centrée et réduire. Nous obtenons donc les données du tableau 2 avec X1 et x2 comme nouvelles variables. Dans le cours les écart type utilisés sont faux. Ici on utilisera les écat type du cour  afin d'avoir les mêmes résultats que dans le cours.

```{r message=FALSE,echo=FALSE}
#Matrice des corrélations
kable(round(cor(X),3),caption = "Matrice des corrélations" ) #3
```

La première matrice que nous avons est la matrice des correlélations. On trouve avec le tableau 3 un rapport de corrélation de 0.788 comme dans le cours. Il y a donc une légère corrélation positive entre nos deux variables.


```{r message=FALSE,echo=FALSE}
#Matrice des covariances
n= dim(X)[1]
R <-t(as.matrix(X))%*%as.matrix(X)/(n-1) #cov(X) et non cor(X) comme dit dans le cour

e <- eigen(cor(X))
#dim(e$vectors)

V <- e$vectors #Vecteur Propre 
kable(round(V,3),caption = "Vecteur Propre") #4
```

On calcule ensuite le vecteur propre, qui constitue le tableau 4. On trouve une différence par rapport au résultat du cour. En effet le signe moins n'est pas sur la même valeur dans le cours.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
VP =round(e$values ,3)

VarExpA1 = VP[1]/2 *100
VarExpA2 = VP[2]/2 *100
```

Le premier facteur associé à la valeur propre 1.787, et 0.212 pour le deuxième. On vas donc retrouvée les mêmes valeurs de pourcentages de variance expliquées , 89.4% pour l'axe 1 et 10,6% pour l'axe 2. On conservera ces deux axes.

```{r message=FALSE,echo=FALSE}
#Coordonnée des variables
Cord_Axe1 = sqrt(VP[1])*V[,1] #Coordonée de X1 et X2 sur l'axe 1
Cord_Axe2 = sqrt(VP[2])*V[,2] #Coordonée de X1 et X2 sur l'axe 1
Cord = cbind(Cord_Axe1,Cord_Axe2)
rownames(Cord) = c("X1","X2")
kable(round(Cord,3),caption = "Coordonnées des variables") #5
```

On peut calculer les coordonées de nos deux variables. Nous trouvons avec le tableau 5 que les coordonées de X1 seront de 0.944 sur l'axe 1 et -0.326. Et pour X2, 0.947 sur l'axe 1 et 0.325 pour l'axe 2.Par rapport au résultat du cours on retrouve le même problème vis-à-vis du signe moins.


```{r message=FALSE,echo=FALSE}
#Coordonnée des individus
Fbis <- as.matrix(X)%*%V
colnames(Fbis) =  c("X1","X2")
rownames(Fbis) =1:5
kable(round(Fbis,3),caption = "Coordonnée des individus") #6
```

Il nous reste plus que les Coordonnées des individus. Ont les retrouvent dans le tableau 6. Les individus 1 et 5 contribuent fortement à l'axe 1, tandis que l'individu 2 contribus le plus à l'axe 2.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pr1 <- princomp(Z,cor=T)
res.pr2 <- prcomp(Z,scale=TRUE)
```

Nous allons maintenant comparer 2 fonctions qui réalise des ACP sous R. Il s'agit de princomp et prcomp. On concervera les données précedente.

```{r message=FALSE,echo=FALSE}
#Valeur Propre

# princomp
kable(round(get_eigenvalue(res.pr1),3), caption = "Valeur propre avec princomp") #7
kable(round(get_eigenvalue(res.pr2),3) , caption = "Valeur propre avec prcomp") #8
```

On commence avec les valeurs propres. On voit les sorties des deux fonctions dans les tableau 7 et 8, et on remarque que les sorties sont excatement les mêmes.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
# princomp
ind1 = get_pca_ind(res.pr1) #individus
var1 = get_pca_var(res.pr1) #variable

#prcomp
ind2 = get_pca_ind(res.pr2) #individus
var2 = get_pca_var(res.pr2) #variable
```

```{r message=FALSE,echo=FALSE}
kable(round(var1$coord,3), caption = "coordonnées des variables avec princomp") #9
kable(round(var2$coord,3) , caption = "coordonnées des variables avec prcomp") #10
# coordonnées des variables pour créer un nuage de points.
```

Pour les coordonnées des variables on voit dans les tableaux 9 et 10, les sorties des deux fonction sont les mêmes. A noté qu'avec ces deux fonctions le signe moins est comme dans le cours. On vas voir que cela est différent avec la fonction PCA.

```{r message=FALSE,echo=FALSE}
kable(round(var1$cos2,3), caption = "Cos2 des variables avec princomp")
kable(round(var2$cos2,3),caption = "Cos2 des variables avec prcomp")
# Représente la qualité de représentation des variables sur le graphique de l’ACP.
```

Pour les qualités de représentations des variables (cos2) des variables on voit dans les tableaux 10 et 11, les sorties des deux fonctions sont les mêmes.

```{r message=FALSE,echo=FALSE}
kable(round(var1$contrib,3), caption = "Contribution des variables avec princomp")
kable(round(var2$contrib,3),caption = "Contribution des variables avec prcomp")
#contient les contributions (en %), des variables, aux composantes principales
```

Et Pour finir la contributions des variables est aussi la mêmes entre les deux fonctions.

```{r message=FALSE,echo=FALSE}
kable(round(ind1$coord,3), caption = "Coordonées des individus avec princomp")
kable(round(ind2$coord,3),caption = "Coordonées  des individus avec prcomp")
```

Pour les individus maintenant. C'est la que l'on retrouve des différences. Deja pour les coordonnées on trouve des dissimilarité ont le voit dans les tableau 15 et 16.

```{r message=FALSE,echo=FALSE}
kable(round(ind1$cos2,3), caption = "Cos2 des individus avec princomp")
kable(round(ind2$cos2,3),caption = "Cos2  des individus avec prcomp")
```

Cepandant les qualités de représentation des individus (cos2) sont les mêmes d'une fonction à une autre.

```{r message=FALSE,echo=FALSE}
kable(round(ind1$contrib,3), caption = "Contributions des individus avec princomp")
kable(round(ind2$contrib,3),caption = "Contributions  des individus avec prcomp")
```

Et pour les contributions, on remarques dans les tableaux ci-dessus que les valeurs sont différentes.

Les plus grosses différences entre princomp et prcomp ce font au niveau des individus et non pour les variables. Regardons maintenant les résultats avec la fonction PCA.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pca = PCA(Z, graph = F) #centre réduit automatiquement
```



```{r message=FALSE,echo=FALSE}
#Valeur Propre
kable(round(get_eigenvalue(res.pca),3), caption = "Valeur propre avec PCA") #20
```

Pour les valeurs propres, on retrouve encore les résultats précedents comme le montre le tableau 21. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ind = get_pca_ind(res.pca) #individus
var = get_pca_var(res.pca) #variable
```

```{r message=FALSE,echo=FALSE}
kable(round(var$coord,3), caption = "coordonnées des variables avec PCA") 
```

Pour les coordonées des variables on voit dans le tableau 21 que le signe moins est placé comme pour l'ACP à la main. Plus exactenement ce signe change de position si on utilise les données centrées réduites, hors ceci est fait automatiquement dans cette fonction.


```{r message=FALSE,echo=FALSE}
kable(round(var$cos2,3), caption = "Cos2 des variables avec PCA")
kable(round(var$contrib,3), caption = "Contributions des variables avec PCA")
```

Pour les qualités de représentation des variables et les contributions, pas de problème on retrouve les mêmes résultats avec les 3 fonctions.


```{r message=FALSE,echo=FALSE}
kable(round(ind$coord,3), caption = "Coordonées des individus avec PCA")
```

Maintenant regardons les résultats de PCA avec les individus. Pour les coordonnées la fonction PCA s'accorde avec la fonction princomp.

```{r message=FALSE,echo=FALSE}
kable(round(ind$cos2,3), caption = "Cos2 des individus avec PCA")
```

Pour le cos2, la fonction PCA s'accorde avec toutes les autres méthodes.


```{r message=FALSE,echo=FALSE}
kable(round(ind$contrib,3), caption = "Contributions des individus avec PCA")
```
Et pour finir le tableau ci-dessus nous montre que les contributions de la fonction PCA sont les mêmes qu'avec la fonction princomp.

On en déduit que les fonctions PCA et princomp réalise l'ACP de la même façon.


## Exercice 24

Dans cette partie on traitera des données des stations de ski en Savoie. On dispose, pour 32 stations, des variables suivantes (données 1998).

— prixforf : prix du forfait 1 semaine (Euros)

— altmin : altitude minimum de la station (m)

— altmax : altitude maximum de la station (m)

— pistes : nombre de pistes de ski alpin

— kmfond : nombre de kilomètres de pistes de ski de fond remontee : nombre de remontées
mécaniques


```{r message=FALSE,echo=FALSE}
data=read.csv("C:/Users/ilias/OneDrive/Bureau/AD/stations.txt", sep="")
data = data[2:6]
attach(data)
kable(head(data),caption = "Extrait des données Station")
```

Voici un extrait des données que nous traiterons.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pca.station = PCA(data , graph = FALSE) #centre réduit automatiquement
```


### Valeurs propres :

Mesurent la quantité de variance expliquée par chaque axe principal.
Nous examinons les valeurs propres pour déterminer le nombre de composantes principales à prendre en considération. 

```{r message=FALSE,echo=FALSE}
VP = round(get_eigenvalue(res.pca.station) , 3)
kable(VP, caption = "Valeurs propres")
#Extraction des valeurs propres/variances des composantes principales.
```

```{r message=FALSE,echo=FALSE, fig.cap= "Visualisation des valeurs propres"}
fviz_eig(res.pca.station , addlabels = TRUE)
#Visualisation des valeurs propres.
```

On voit avec le tableau et figure ci-dessus qu'avec 3 axes ont obtion une variance expliquée de presque 90%, ce qui est suffisant. On concervera donc les 3 premières dimension. 


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ind.station = get_pca_ind(res.pca.station) #individus
var.station = get_pca_var(res.pca.station) #variable
#retourne une liste d’éléments contenant tous les résultats pour les variables ou individus actives
```

### variables :

```{r message=FALSE,echo=FALSE}
CV = round(var.station$coord ,3)
kable(CV, caption = "coordonnées des variables")
# coordonnées des variables pour créer un nuage de points.
```

Le tableau suivant montre les valeurs des coordonnées afin de crée un cercle des corrélations.

```{r message=FALSE,echo=FALSE}
QR = round(var.station$cos2 ,3)
kable(QR, caption = "Qualité de représentation des variables ")
# Représente la qualité de représentation des variables sur le graphique de l’ACP.
```


```{r}
#visualiser le cos2 des variables 
corrplot(var.station$cos2, is.corr=FALSE) #Corrélogramme sur toutes les dimensions
#ou 
#fviz_cos2(res.pca.station, choice = "var", axes = 1 :2) 
#diagramme en barre ici on considère l'axe 1 et 2
```
Ensuite on regarde qualité de représentation des variables pour chaque dimension à l'aide du graphique et tableau ci-dessus. On voit pas exemple que les variables prixforf et piste sont très bien représenté sur l'axe 1.

```{r message=FALSE,echo=FALSE}
round(var.station$contrib,3)
#contient les contributions (en %), des variables, aux composantes principales
```

```{r message=FALSE,echo=FALSE}
#visualiser les contribution des variables 

#corrplot(var.station$contrib, is.corr=FALSE) #chaque dimension

#ou

#Si vos données contiennent de nombreuses variables, vous pouvez décider de ne montrer que les principales variables contributives. avec les barplot.

#La ligne en pointillé rouge, sur le graphique ci-dessus, indique la contribution moyenne attendue. (1/nb_variable). une variable avec une contribution supérieure à ce seuil pourrait être considérée comme importante pour contribuer à la composante.

#fviz_contrib(res.pca.station, choice = "var", axes = 1, top = 5) 
# ici pour 10 variables sur l'axe 1

fviz_contrib(res.pca.station, choice = "var", axes = 1:2, top = 5)
# ici pour 10 variables sur l'axe 1 et 2

```
On s'interesse maintenant à la contribution des variables. On voit avec le tableau les contribution de chaque variabes pour chaque dimension. Par exemple la variable prixforf contribue à 36.7% de l'axe 1. Le graphique nous montre ces contribution pour le premier plan. La ligne rouge indique la contribution moyenne attendue. Toute les variables qui dépasse cette ligne considérée comme importante pour contribuerau premier plan.

```{r message=FALSE,echo=FALSE}
#Cercle de corrélation pour les variables on represente les coordonéees, la proximité d'une fleche au cercle indique le cos2
fviz_pca_var(res.pca.station, axis = c(1,2),repel = TRUE, col.var = "cos2" , gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), axes = c(1,2), alpha.var = "contrib"
             )
#paramètre :

# col.var = "cos2" : Color par rapport au cos2
# col.var = "contrib" : Color par rapport au contribution
# gradient.cols= ... : couleur qu'on veut
# repel : évite le chevauchement de texte
#alpha.var = "cos2" : transparence de la fleche selon le cos2
#alpha.var = "contrib" : transparence de la fleche selon la contribution

# col.var = ... : possible de colorer les variables par n’importe quelle variable continue personnalisée.

#On peut aussi coloré par groupe de variable qualitative ou crée des groupes si on en à pas par exemple avec enutilisant l’algorithme de classification k-means :
# res.km <- kmeans(var$coord, centers = 3, nstart = 25)
# grp <- as.factor(res.km$cluster)
# col.var = grp 

#Argument en plus :

# geom.var = "point", pour afficher uniquement les points 
#geom.var = "text" pour afficher uniquement le texte d’annotation des points
# geom.var = c("point", "text") pour afficher à la fois les points et le texte
#geom.var = c("arrow", "text") pour afficher les flèches et les annotations (par défaut).

#pointshape = ... : Forme du point (ggpubr ::show_point_shapes() pour plus de formes de points)
#labelsize : taille du texte, par exemple : labelsize = 4.
#pointsize : taille des points, par exemple : pointsize = 1.5.
#arrowsize :  Contrôle l’épaisseur des flèches, par exemple : arrowsize =0.5.

#axes.linetype = ... : utilisé pour spécifier le type de trait des axes.(toutes les valeurs possibles ggpubr ::show_line_types())
#axes.linetype = "blank" pour les supprimé
```
On peut représenter l'ensemble de ces résultats dans le cercle des corrélation, ici on s'interesse au premier plan. Pour la qualité de représentation (cos2) on à une variation de couleur selon son importance sur le premier plan. On voit que les variables prixfof et piste sont celle qui sont le mieux représenter dans ce plan. la transparence des flèches indique la contributions. Par exemple la variable kmfond n'as pas une grande contribution sur le premier plan. Les fleches des variables prixfof et piste sont très proches ce qui indique un lien fort positif entre ces deux variables. Tandis que atmin et kmfond son pratiquemennt opposée ce qui signifie un lien fort négatif. 


### individus :

```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$coord,3)), caption = "Extrait des coordonées des individus")
# Coordonnées des individus
```

On s'interesse maintenant aux individus. On commence par montrer leurs coordonées qu'il auront sur chasque dimension sur le tableau ci-dessus. Ici il n y a pas l'ensemble des individus représentés.

```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$cos2,3)), caption = "Extrait des cos2 des individus")
# Qualité des individus
```


```{r}
#bar plot de la qualité de représentation (cos2) des individus
fviz_cos2(res.pca.station, choice = "ind", axes = 1:2)
```
On regarde maintenant les qualités de représentation pour les différentes dimensions, qu'on retrouve dans le tableau. Le graphique nous illustre ces valeurs pour le premier plan, on voit que c'est l'individu 10 qui est le mieux représenter sur ce plan suivis du 1 et du 32. Nous allons les retrouver après dans le graphique.



```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$contrib,3)), caption = "Extrait des contributions des individus")
# Contributions des individus
```

```{r message=FALSE,echo=FALSE}
#visualiser la contribution des individus aux deux premières composantes principales
fviz_contrib(res.pca.station, choice = "ind", axes = 1:2)
```
On s'interesse maintenant à la comtributions des individus. On voit dans le tableau les contributions des individus sur les différents axes. Le graphique montre les individus qui contribue le plus au premier plan. L'individu 24 est celui qui à la plus forte contribution sur ce plan. Tout les individus au-dessus de la ligne poitillée rouge peuvent être considéré comme importante pour contribuer au premier plan.


```{r message=FALSE,echo=FALSE}
#graphique des individus
fviz_pca_ind(res.pca.station, col.ind = "cos2", pointsize = "contrib",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07",'red',"black"), repel = TRUE)

# col.ind = "cos2" : Color par rapport au cos2
# col.ind = "contrib" : Color par rapport au contribution
# gradient.cols  : couleur qu'on veut
# pointsize = "cos2" : taille des point en fonction du cos2
#pointshape = ... : Forme du point (ggpubr ::show_point_shapes() pour plus de formes de points)
#fill = "#E7B800" : Color les cercle vide
# repel : évite le chevauchement de texte

#POUR MODIFIER LA TAILLE ET LA COULEUR DES POINTS EN FONCTION DU COS2 :
#fviz_pca_ind(res.pca, col.ind = "cos2", pointsize = "cos2",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE )

#Argument en plus :

#geom.ind = "point", pour afficher uniquement les points ;
#geom.ind = "text" pour afficher uniquement le texte d’annotation des individus
#geom.ind = c("point", "texte") pour afficher à la fois les points et le texte d’annotation (valeur par défaut)

#labelsize : taille du texte, par exemple : labelsize = 4.
#pointsize : taille des points, par exemple : pointsize = 1.5.

#axes.linetype = ... : utilisé pour spécifier le type de trait des axes.(toutes les valeurs possibles ggpubr ::show_line_types())
#axes.linetype = "blank" pour les supprimé

```
On peut maintenant tracer le nuage de points des individus sur le premier plan. Chaque points a une épaissseur proportionnelle  à sa contribution. On retrouve les individus 24, 10 et 16 qui sont les plus gros points et qui contribuent le plus. De plus nous pouvons voir une couleur plus chaude quand la qualité de représentation (cos2) est élevé, et inversement. Les individus 10,1,24,6,22,8, et 32 sont de couleur noir qui correspond à une très bonne qualité de représentation sur ce plan. 



### Variable & individus :
```{r}
#Création d’un biplot des individus et des variables.
fviz_pca_biplot(res.pca.station,col.var = "#2E9FDF",col.ind = "#696969") 

```

Pour finir on va analyser les individus et les variables ensembles sur le premier plan, en suppersant les deux graphquiques précedent. Ils nous apprend qu'elle sont les individus qui ont une forte valeur selon les variables. Pour la variable altmax par exemple, les indivus 29, 12, 21, sont ceux qui ont une forte valeur pour cette variable. Et inversement, on peut savoir quels individus ont une faible valeur pour une variable. Les individus 27, 25, 26 par exemple sont opposée à la fleche de la variable kmfond, ceux qui indiques une faible valeur de ces individus pour cette variables.







