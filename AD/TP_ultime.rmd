---
#title : "Rapport d'Analyse de données"
#author : "LEUCHI Ilias"
output:
  pdf_document:
    toc : true
    extra_dependencies : ["float"]
---



```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
library(knitr)
library(car)
library(MASS)
library(ggpubr)
library(lattice)
library(corrplot)
library("FactoMineR")
library("factoextra")
library(ca)
```



\newpage

# Chapitre 1 : Prise en main et algèbre

## Exercice 13

Un échantillon de dossiers d’enfants a été saisi. Ce sont des enfants vus lors d’une visite en 1ère section de maternelle en 1996-1997 dans des écoles de Bordeaux (Gironde, France). L’échantillon est constitué de 152 enfants âgés de 3 ou 4 ans. Les variables sont : le poids de naissance de l’enfant (variable quantitative BWT, exprimée en grammes), l'age de la mère, le poids de la mère lors du dernier cycle menstruel, la “Race” de la mère, le tabagisme durant la grossesse, le nombre d’antécédents de prematurité, l'antécédents d’hypertension, la présence d’irritabilité utérine, le nombre de visites à un médecin durant le premier trimestre de la grossesse, le poids de naissance et le poids de naissance inférieur ou égal à 2500 g.

```{r message=FALSE,echo=FALSE}
data=read.csv("C:/Users/ilias/OneDrive/Bureau/AD/Poids_naissance.txt", sep=";")

attach(data)

kable(head(data),caption = "Extrait des données")
 
#Matrice des données
```

Le tableau 1 est un court extrait du jeu de données. Ici la variable LWT, qui correspond au poids de la mère, est exprimée en livres, nous le modifions donc pour l’avoir en kilogrammes.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
data$LWT = round(data$LWT*0.45359237,3)  #transforme le poids de la mama en Kg
```

```{r message=FALSE,echo=FALSE}
kable(head(data), caption = "Extrait des données avec chagement d'unité du poids de la mère")
```

Nous obtenons le jeu de données du tableau 2.

\newpage 

Réalisons maintenant quelque tri à plats avec ces données.


```{r message=FALSE,echo=FALSE}
decoup_age =cut(AGE, breaks =5)
kable(table(decoup_age), caption = "Tri à plat de l'âge de la mère"
      ,col.names = c("classes","Effectifs"))
```

Avec l'âge de la mère, on remarque dans le tableau 3 que 74 des enfants de nos données ont une mère agée entre 20 et 26 ans. 

```{r message=FALSE,echo=FALSE}
decoup_LWT = cut(data$LWT, breaks = 5)
kable(table(decoup_LWT), caption = "Tri à plat du poids de la mère",
      col.names = c("classes","Effectifs"))
```

Le tableau 4 nous apprend que 87 mères des enfants de nos données, ont un poids qui se situe entre 51.7 et 67.1 kg.

```{r message=FALSE,echo=FALSE}
#Recodage de la variabe Race
RACE = factor(RACE)
levels(RACE)=c("Blanche","Noir","Autre")
kable(table(RACE), caption = "Tri à plat de la race de la mère",
      col.names = c("Race","Effectifs"))
```

Le tableau 5 nous indique que 96 mères des enfants des données ont une race dite "Blanche".

```{r message=FALSE,echo=FALSE}
SMOKE=factor(SMOKE)
levels(SMOKE)=c("Non", "Oui")
kable(table(SMOKE), 
      caption = "Tri à plat du tabagisme durant la grossesse",
      col.names = c("Tabagisme","Effectifs"))
```

Et pour finir 74 enfants de nos données, avaient une mère qui fumé durant sa grossesse, comme nous indique le tableau 6.

\newpage 

## Exercice 14

Nous allons créés un jeu de données personnelles, l'objectif sera de voir les manipulations possibles sur des données.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
Mort.a <- c(93,53,72,68,68,53)
Années.de.carrière <- c(66,25,48,37,31,32)
Nombre.de.films <- c(211,58,98,140,74,81)
Prénom <- c("Michel", 
            "André",
            "Jean" ,
            "Louis" ,
            "Lino",
            "Jacques")

Nom <- c(
          "Galabru"   ,
          "Raimbourg",
          "Gabin",
          "De Funès",
          "Ventura" ,
          "Villeret")

Date.du.deces <- c("04-01-2016",
                    "23-09-1970",
                    "15-10-1976",
                    "27-01-1983",
                    "22-10-1987",
                    "28-01-2005")
```


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
acteur=data.frame(Mort.a,Années.de.carrière, Nombre.de.films,Prénom,Nom,Date.du.deces ) 
```


```{r message=FALSE,echo=FALSE}
kable(acteur,caption = "Jeu de données") #7
```

Le tableau 7 nous illustre le jeu de données. Chaque individu correspond à un acteur ou on retrouve son nom, prénom, son nombre d'années de carrière, son nombre de films, et la date de sa mort avec l'âge.
 
```{r message=FALSE,echo=FALSE}
kable(acteur[4], caption = "Prénom du jeu de données") #8
```

Nous pouvons extraire une colonne en particulier, dans le tableau 8 c’est « prénom » qui est extrait.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
colnames(acteur)[1] = c("Age.du.décès")
acteur
```
 
```{r message=FALSE,echo=FALSE}
kable(acteur[order(acteur$Age.du.décès),], 
      caption = "Données trié par l'âge du décès") #9
```

Nous modifions ensuite le nom de la colonne « Mort.a » , en « Age.du.décès », comme le montre le tableau  9. Et pour finir, nous pouvons ordonner le jeu de données selon une condition. Ici nous voulons ordonner par « Age.du.décès » croissant, ce qui est fait dans le tableau 9 également.

\newpage

## Exercice 15

Le goût d’un fromage dépend de la concentration de plusieurs composés chimiques, dont : la concentration d’acide acétique (variable X1), la concentration d’hydrogène sulfuré (variable X2), la concentration d’acide lactique (variable X3). Pour 30 types de fromage, on dispose du score moyen attribué par des goûteurs (caractère Y).

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
w =read.delim("C:/Users/ilias/OneDrive/Bureau/AD/fromage.txt")

attach(w)
```

```{r message=FALSE,echo=FALSE}
kable(head(w), caption = "Extrait du jeu de données fromage") #10
```

Voici un extrait des données représentées dans le tableau 10 .On retrouve bien un total de 30 individus qui correspondent à des types de fromage. Il y a bien les 4 variables toutes quantitatives. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
X1
```


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
dim(w)
str(w)
attributes(w)
```

```{r message=FALSE,echo=FALSE}
kable(summary(w),
      caption = "Statistiques élémentaires des données fromage") #11
```

Le tableau 11 nous montre les statistiques élémentaires pour chacune des variables. Par exemple pour Y on trouve une valeur moyenne de 24.53, un minimum de 0.7 et un maximum de 57.20.

\newpage 

```{r message=FALSE,echo=FALSE, fig.cap= "Ozone en fonction des saisons", out.width="80%",fig.align="center"}
pairs(w, main= "Matrice des nuages de points", cex.main =1)
```

La figure 1 représente la matrice de nuage de points entre chacune des variables. Ce sont les nuages de points des croisements deux à deux entre chaque variable de nos données. 

```{r message=FALSE,echo=FALSE}
ww<- w[X1 > 5.1 & X3 < 1.77,]
kable(head(ww), caption = "Extrait des données fromage filtrées") #12
```

Nous allons maintenant créer un sous-jeu de données avec les contraintes suivantes : X1 > 5.1 et X3 < 1.77. C’est ce qui est représenté dans le tableau 12.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
dim(ww)
str(ww)
attributes(ww)
```

```{r message=FALSE,echo=FALSE}
kable(summary(ww),
      caption = "Statistiques élémentaires des données fromage filtrées") #13
```

Après ce changement on trouve certaines valeurs différentes des statistiques élémentaires, par exemple la moyenne de Y est maintenant de 23.52. Nous voyons les nouvelles statistiques dans le tableau 13.

\newpage

## Exercice 16

Les données que nous utiliserons sont directement implantées dans R, il s’agit des données «airquality».

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
data = airquality
#?airquality
attach(data)
```

```{r message=FALSE,echo=FALSE}
kable(head(data), caption = "Extrait des données airquality") #14
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
names(data)
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
dim(data)
```

Le tableau 14 nous montre un extrait des données.
Il s’agit des relevés quotidiens des valeurs de qualité de l'air, du 1er mai 1973 au 30 septembre 1973. Il y a 153 individus pour 6 variables : Ozone taux d’ozone en ppb (parts per billion), Solar.R Rayonnement solaire (langleys), Wind Vitesse du vent (miles par heure)
Temp température (degrés Fahrenheit), Month mois (entre 1 et 12), Day jour du mois (entre 1 et 31). Les données ont été obtenues auprès du New York State Department of Conservation (données sur l'ozone) et du National Weather Service (données météorologiques).


```{r message=FALSE,echo=FALSE}
kable(summary(data[1:4]), 
      caption = "Statistiques élémentaires des données") #15
```

Le tableau 15 nous montre les statistiques élémentaires sur nos variables quantitatives, ainsi que les valeurs manquantes. Pour la variable ozone on remarque 37 valeurs manquantes et une moyenne de 42.13.

\newpage

```{r message=FALSE,echo=FALSE, , out.width="80%",fig.align="center",fig.cap= "boîte à moustaches de l’Ozone pour chaque mois"}
plot(Ozone~factor(Month),col=c(2:6),
     main="boîte à moustaches de la variable Ozone pour chaque mois"
     ,cex.main = 1,xlab = "Mois" )
```

On remarque, grâce à la figure 2, des diagrammes à moustache avec une tendance similaire pour les mois 5, 6, et 9, qui ont des valeurs de l’ozone peu élevées, qui varie moins. Alors que pour les mois 7 et 8, les valeurs de l’ozone sont plus fortes et beaucoup plus réparties.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
data$saison =factor(Month)
levels(data$saison )
levels(data$saison)[5]="automne"
levels(data$saison)[1] ="printemps"
levels(data$saison)[2:4]="été"
```


```{r message=FALSE,echo=FALSE}
kable(head(data), 
      caption = "Extrait des données avec la saison") #16
```

Pour notre analyse, nous rajoutons une variable saison. Le tableau 16 montre nos données avec cette nouvelle variable.

\newpage

```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center", fig.cap= "Ozone en fonction des saisons"}
scatterplot(Ozone~Temp|saison, data = data, 
            regLine =FALSE, grid =F,smooth = FALSE, legend = FALSE,
            main ="Ozone en fonction du temps selon les saisons", cex.main =1,
            col=c("blue","green","red"),pch=c(3,2,1),xlab = "Temps")

legend("topleft",levels(data$saison),cex=.8,col=c("blue","green","red"),pch=c(3,2,1), text.font=4)

```

Avec la figure 3 on remarque qu’il y a une relation positive linéaire croissante entre l’ozone et le temps. Cette relation est présente pour chacune des saisons. Le temps est plus élevé en été et plus faible en hiver. Et comme vu précédemment avec la figure 2, la concentration d’ozone est plus forte en été, qui correspond aux mois 7 et 8.

\newpage

## Exercice 17

Nous nous intéressons à la fonction suivant $yi = 1.7+2.1 i + ei$ , avec $i$ entre 1 et 100, et les $ei$ suivant une lois $N(0,5²)$.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ech = rnorm(100,1,5)
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
i =1:100
yi = function(i,ech) {1.7+2.1*i + ech}
```


```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center", fig.cap= "Nuage de points des yi en fonction de i"}
#scatterplot(i~yi(i,ech), regLine= TRUE, boxplot= F,smooth = FALSE)

plot(yi(i,ech)~i,pch= 3, col="blue"
     ,main = "nuage de points des yi en fonction de i", ylab = "yi", cex.main = 1)
abline(lm(yi(i,ech)~i), col = "red")
```

La figure 4 nous montre le nuage de points généré avec notre fonction, avec la droite de régression. Cette droite semble être un bon ajustement de notre fonction.

\newpage

## Exercice 18

On considère un tableau de contingence obtenu en ventilant 592 femmes suivant la couleur de leurs yeux et la couleur de leurs cheveux.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
colCheveaux<-c(rep("brun",68+15+5+20),
               rep("châtain",119+54+29+84),
               rep("roux",26+14+14+17),
               rep("blond",7+10+16+94))
```
```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
colYeux<-c(rep("marron",68),rep("noissette", 15), rep("vert",5),rep("bleu",20),
           rep("marron",119),rep("noissette", 54), rep("vert",29),rep("bleu",84),
           rep("marron",26),rep("noissette", 14), rep("vert",14),rep("bleu",17),
           rep("marron",7),rep("noissette", 10), rep("vert",16),rep("bleu",94))

```
```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
femme =data.frame(colCheveaux,colYeux)
```
```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
n =length(femme[,2])
```


```{r message=FALSE,echo=FALSE}
#Tableau des effectifs croisés (de contingence)
TEC=table(femme$colYeux,femme$colCheveaux)
kable(TEC, caption = "Tableau de contingence du croisement entre la couleur des yeux et des cheveux") #17

```

Le tableau 17 illustre ce tableau de contingence. On apprend par exemple que 94 femmes de nos données sont blondes aux yeux bleus.

```{r message=FALSE,echo=FALSE}
#Tableau des frequence croisés
TFC=round(prop.table(table(femme$colYeux,femme$colCheveaux)),2)*100
kable(TFC, caption = "Matrice des fréquences du croisement entre la couleur des yeux et des cheveux (%)") #18
```

Et voici la matrice des fréquences de nos données dans le tableau 18. On remarque que 11% des femmes de nos données sont brunes aux yeux marron.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#lois marginales de la couleur des yeux
c =addmargins(TEC, FUN = sum)[-5,5]
c
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#lois marginales de la couleur des cheveux
r=addmargins(TEC, FUN = sum)[5,-5]
```


```{r echo=FALSE, message=FALSE}
kable(addmargins(TEC, FUN = sum), caption = "Tableau de contingence avec les marges") #19
```

Nous pouvons ajouter les marges dans notre tableau de contingence comme le montre le tableau 19. Elles nous informent que 215 femmes de nos données ont les yeux bleus, ou encore que 71 d'entre elles sont rousses.

```{r message=FALSE,echo=FALSE}
#Distribution conditionnelle des couleur des cheveux sachant la couleur des yeux
C =sweep(TEC, MARGIN=1,STATS = c,FUN = "/")*100
C =round(addmargins(C,FUN =sum),2)[-5,]
kable(C, caption = "Distributions conditionnelles des couleurs des cheveux sachant la couleur des yeux") #20
```

Le tableau 20 des distributions conditionnelles de la couleur des cheveux, sachant la couleur des yeux, nous apprend par exemple que, 58,06% des femmes aux yeux noisettes ont une couleur de cheveux châtains.

```{r message=FALSE,echo=FALSE}
#Distribution conditionnelle des couleur des yeux sachant la couleur des cheveux
R =sweep(TEC, MARGIN=2,STATS = r,FUN = "/")*100
R =round(addmargins(R,FUN =sum),2)[,-5]
R=R
kable(R, caption = "Distributions conditionnelles des couleurs des yeux sachant la couleur des cheveux") #21
```

Le tableau 21 correspond aux distributions conditionnelles des couleurs des yeux, sachant la couleur des cheveux. On apprend que les femmes brunes ont pour 13.89% d'entre elles les yeux noisette. 



```{r message=FALSE,echo=FALSE}
#matrice taux de liaison

kable(round(cor(TEC),3),caption = "Matrice des taux de liaisons") #22


```

Le tableau 22 nous apprend les liaisons (variant entre -1 et 1), entre les modalités de la variable couleur des cheveux. Par exemple on voit qu'il y a un lien positif entre la couleur châtain et brun, ce qui signifie qu'il y a une tendance similaire entre ces deux modalités vis-à-vis de la couleur des yeux. 

```{r message=FALSE,echo=FALSE}
#Test du khi2
chisq.test(TEC)
```

On réalise un test sur nos deux variables pour savoir elles sont indépendantes. On remarque une pvaleur très proche de zéro.Ce qui nous permet de rejeter l’hypothèse d’indépendance entre la couleur des yeux et celle des cheveux. Il y a donc un lien entre ces deux variables.

\newpage



# Chapitre 2 : Mesure de la liaison entre une variable et un ensemble de variables

## Exercice 19

Nous étudions ici un croisement entre des classes d’âges et des diplômes, pour 90 individus.

```{r message=FALSE,echo=FALSE}
data <- data.frame(BEPC = c(15,10,15,40), BAC = c(12,18,5,35), Licence
= c(3,4,8,15), Total = c(30,32,28,90))
rownames(data) <- c("Plus de 50 ans", "Entre 30 et 50 ans", "Moins de 30 ans", "Total")

kable(data,caption = "Tableau de contingence des l’âges croisé avec les diplômes") #1
```

Le tableau 23 nous donne les effectifs croisés de nos deux variables. On apprend par exemple que dans nos données il y a 40 individus avec un BEPC, et que 15 d'entre eux ont plus de 50 ans. 


```{r message=FALSE,echo=FALSE}
#Tableau de contingence des fréquences
TCF = round(data/90,3)*100
kable(TCF,caption = "Tableau des fréquences croisées (%)") #2
```

On peut obtenir les fréquences de notre tableau 23. C'est ce qu'illustre le tableau 24, on voit par exemple que 35.6% de nos individus ont entre 30 et 50 ans, et 20% d'entre eux ont un bac. 

```{r message=FALSE,echo=FALSE}
#profil ligne en pourcentage (derniere colonne que des 1)
PL = round(sweep(data, MARGIN=1,STATS = data[,4],FUN = "/")*100,2)
kable(PL,caption = "Profils lignes (%)") #3
```

Le tableau 25 nous donne les fréquences sachant la tranche d'âge. On voit que 28.57% des moins de 30 ans ont une licence.

```{r message=FALSE,echo=FALSE}
#profil collone en fréquence (derniere ligne que des 1)

PC =round(sweep(data, MARGIN=2,STATS = t(data[4,]),FUN = "/")*100,2)
kable(PC,caption = "Profils collones (%)") #4
```

Le tableau 26 nous donne les fréquences sachant le diplôme, on apprend que pour ceux ayant un bac, 51.43% ont entre 30 et 50 ans.

```{r message=FALSE,echo=FALSE, warning=FALSE}
chisq.test(data)
```

On cherche à savoir si nos deux variables sont indépendantes. On trouve une pvlaur de 0.2639, une valeur conséquente qui nous permet de conclure sur le non-rejet de H0, et d'en déduire qu'il y a indépendance entre les deux variables.



## Exercice 20

Pour une population d’effectifs de taille 1000 on a mesuré les deux variables qualitatives “Couleur des yeux” et “Etat matrimonial”. 

```{r message=FALSE,echo=FALSE}
tableau <- matrix(c(290,410,110,190), ncol=2, byrow=TRUE)
colnames(tableau) <- c("Bleu","Brun")
rownames(tableau) <- c("Celib","Marie")
tableau <- as.table(tableau)


kable(tableau, caption = "Tableau de contingence de la couleur des yeux et de l'état matrimonial") #5
```

Le tableau 27 nous apprend que parmi nos 1000 individus 290 sont célibataires avec les yeux bleus. Ou encore que 190 sont mariés avec les yeux bruns.


\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap= "Diagramme empilé de la couleur des yeux selon la situation matrimoniale"}

barplot(tableau, col = c("green","red"),  main = "Diagramme empilé de la couleur des yeux selon la situation matrimoniale", cex.main = 1)

legend("topleft", legend= c("celib","marie"), inset=.02,  fill=c("green","red"))
```


On peut rendre graphique le tableau 27. Grâce à la figure 5 on remarque que nous avec moins d'individus aux yeux bleus qu'aux yeux bruns.




```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
n <- margin.table(tableau) # effectif total

m1 <- margin.table(tableau,1) #lois marginale de l'état matrimonial

m2 <- margin.table(tableau,2) #lois marginale de la couleur des yeux

prop.table(tableau) #tableau de contingence en fréquence
```


Quelque commande R utile sur nos données :

n <- margin.table(tableau) => effectif total

m1 <- margin.table(tableau,1) => lois marginale de l'état matrimonial

m2 <- margin.table(tableau,2) => lois marginale de la couleur des yeux

prop.table(tableau) => tableau de contingence en fréquence



```{r message=FALSE,echo=FALSE}
kable(prop.table(tableau)*100, caption = "Tableau de contingence (%)") #6
```

Voici par exemple le tableau de contingence en pourcentage cette fois. On apprend que 41% des individus sont celibataires au yeux bruns.

\newpage

```{r message=FALSE,echo=FALSE}
#Tableau des effectifs tehorique 
tab0 <- as.array(m1) %*% t(as.array(m2))/n 
tab0 <- as.table(tab0)
kable(tab0,caption = "Tableau des effectifs théoriques") #7
```

Le tableau 29 nous montre les effectifs théoriques, c'est-à-dire les effectifs si nos variables étaient parfaitement indépendantes.

```{r message=FALSE,echo=FALSE}
summary(tableau)
```

La statistique du $\chi^2$ mesure l'écart entre le tableau de contingence et le tableau des effectifs théoriques. 

Les résultats du test du $\chi^2$ indiquent une pvaleur supérieur à 0.05 ce qui ne nous permet pas de rejetter H0, l'hypothèse d'indépendance.

```{r message=FALSE,echo=FALSE}
summary(tab0)
```

Si on réalise le test sur le tableau des effectifs théoriques, on trouve une pvaleur de 1. Ce qui prouve que ces données reflète l'indépendance parfaite.  


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
tableau2 <- matrix(c(0,600,400,0), ncol=2, byrow=TRUE)
colnames(tableau2) <- c("Bleu","Brun")
rownames(tableau2) <- c("Celib","Marie")
tableau2 <- as.table(tableau2)
tableau2
```

```{r message=FALSE,echo=FALSE}
chisq.test(tableau2)
```

quand on réalise le test sur un tableau truqué, où tous les individus aux yeux bleus sont mariés et tous les autres sont célibataires, on trouve une pvaleur très petit. Donc un rejet de H0, il y a une forte dépendance entre les deux variables.


\newpage

## Exercice 21

Pour cet exercice nous utiliserons le jeu de données "cars" directement implanté dans R.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
data(cars)
#?cars
names(cars)
dim(cars)
#Que représente ce jeu de données (attention aux unités) ?
#Comment doit-on appeler les variables ?
#Quelle est la taille de la matrice ? 
```

```{r echo=FALSE, message=FALSE}
kable(head(cars),caption = "Extrait du jeu de données cars") #8
```


Ces données indiquent la vitesse de 50 voitures et les distances nécessaires pour s'arrêter. Notez qu'elles ont été enregistrées dans les années 1920. Nous retrouvons un extrait de ces données dans le tableau 30.

La matrice contient 50 lignes et 2 colonnes. Il y a donc deux variables qui sont "speed" la vitesse en mph, et "dist" la distance d'arrêt en ft.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
reg<-lm(dist~speed,cars)
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
# plot(cars)
# #Deux variable quanti, nuage de points RAS c'est bon !
# reg<-lm(dist~speed,cars)
# attributes(reg) #Sa carte d’identité
# summary(reg)
# anova(reg)
# #On retrouve la meme pvaluer et la meme statistique de test entre anova(reg) et summary(reg).
# names(reg)
# p =plot(reg)
#4 graphiqueson n’en connait qu’un, éventuellement deux (les graphiques 1 et 3) mais le 2 et le 4 sont sans doute inconnus.

#Le graphique 2 (QQ-plot) permet de vérifier l’hypothèse de normalité des résidus : si les points sont à peu près alignés en se confondant avec la première bissectrice des axes, on peut dire que les résidus suivent une loi normale.

#Le graphique 4 (Cook’s D) permet de repérer les points ń influents ż, c’est-à-dire ceux pour qui la régression linéaire est mal (ou pas) adaptée, parce qu’ils se situent trop loin de la droite de régression. Ces points sont repérés par de grandes valeurs du D de Cook

```

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap="Nuage de points de la distance d'arrêt et la vitesse"}

plot(cars, pch = 20, col="blue", 
     main ="Nuage de points de la distance d'arrêt et la vitesse", cex.main = 1)

abline(reg=reg,col="red") #ou abline(reg$coeff,col="yellow")
```

Un nuage de points est une bonne représentation entre deux variables quantitatives. La figure est donc adaptée à nos données. Les points semblent liés linéairement de manière positive et croissantes. La droite de régression, en rouge, est celle qui passe le plus près de tous les points.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
predict(reg,data.frame(speed=20)) 
```

Le modèle prédit une distance de freinage de 61.07 ft pour une vitesse de 20 mph.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
id= predict(reg,data.frame(speed=20),interval = "confidence") #intervalle de confiance


paste("[",round(id[2],2),",",round(id[3],2),"]")
```
```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
id= predict(reg,data.frame(speed=20),interval = "predict" ) #l'intervalle de prédiction

paste("[",round(id[2],2),",",round(id[3],2),"]")
```
\newpage

Intervalle de confiance : [ 55.25 , 66.89 ]

Intervalle de prédiction : [ 29.6 , 92.54 ]

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#L’exemple cars est-il adapté à la sélection de modèles ? Oui
```

L’exemple cars est adapté à la sélection de modèles.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#?update
```

update() : Va mettre à jour et par défaut réajuster un modèle. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#?step
```

step() : Sélectionnez un modèle basé sur une formule par AIC.



## Exercice 22

Nous utiliserons des données extraient d’un recueil issu d’une enquête portant sur une population d’enseignants de collège.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#Donnee sur enseignant
library(readxl)
data<- read_excel("C:/Users/ilias/OneDrive/Bureau/AD/Donnees sur enseignants.xls")
attach(data)
```

```{r message=FALSE,echo=FALSE}
kable(head(data),caption = "Extrait des données")
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
dim(data)
#168 individus , 11 variables 
names(data)
#Nom des variables
```

Le tableau 31 est un extrait des données que nous utiliserons. Il y a un total de 11 variables, pour 168 individus. La plupart des variables sont explicites. Le salaire est exprimé en euros, l’âge et l’ancienneté en année. Le stress, l’estime de soi et la satisfaction au travail sont mesurés sur des échelles allant de 0 à 50 suivants des techniques appropriées.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
summary(data)
```

```{r message=FALSE,echo=FALSE}
kable(summary(data[,7]),caption = "Résumé statistique du salaire")
```

Quand on s'intéresse de près aux salaires dans nos données, grâce au tableau 32, on trouve un minimum de 1200€, un maximum de 2200€, et un salaire médian de 1720€.

\newpage 

### Croisement qualitatif vs qualitatif : Sexe et EtatCivil

Essayons de croiser deux variables qualitatif, avec le sexe et l'état civil.

```{r message=FALSE,echo=FALSE}
#Tableau de contingence en effectif 
TDC_E_1 =table( Sexe,EtatCivil)
TDC_E =addmargins(TDC_E_1,FUN = sum)

kable(TDC_E, caption = "Tableau de contingence entre le sexe et l'état civil") #3
```

On commence par croiser les effectifs de nos deux variables dans le tableau 33. On apprend par exemple que sur les 168 hommes de nos données, 89 sont mariés.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#Tableau de contingence en fréquence 
TDC_F_1 =round(prop.table(TDC_E_1),3)
TDC_F =addmargins(TDC_F_1,FUN =sum)
```

```{r message=FALSE,echo=FALSE}
#Tableau de contingence en pourcentage 
TDC_P_1 =round(prop.table(TDC_E_1)*100,3)
TDC_P =addmargins(TDC_P_1,FUN =sum)

kable(round(TDC_P,2), caption = "Tableau des fréquences croisées entre le sexe et l'état civil (%)") #4

```

Le tableau 34 nous donnes les pourcentages du croisement entre nos deux variables. On remarque que 73.84% de nos individus sont mariés dont 22.62% sont des femmes.

\newpage 

```{r message=FALSE,echo=FALSE,out.width="60%",fig.align="center", fig.cap= "Ballonplot du croisement entre sexe et état civil"}

ggballoonplot(TDC_E, col = "white",fill = "value", color = "lightgray",
              size = 10, main = "Ballonplot du croisement entre sexe et état civil", 
              cex.main = 1,
              show.label = TRUE) +
  gradient_fill(c("blue", "white", "red"))

```

```{r message=FALSE,echo=FALSE,out.width="60%",fig.align="center", fig.cap= "Diagramme en barre du croisement entre sexe et état civil"}
barplot(TDC_P_1, beside=TRUE, col= c("pink",4),
        ylim = c(0,60),ylab = "pourcentage",
        main = "Diagramme en barre du croisement entre sexe et état civil",
        cex.main = 1,legend.text = c("Femme","Homme")) #2
```

Nous pouvons rendre graphique les résultats de nos tableaux de contingence, comme le font les figures 7 et 8.

\newpage

```{r message=FALSE,echo=FALSE}
#Profil Collone 
PC = round(sweep(TDC_E, MARGIN=2,STATS = t(TDC_E)[,3],FUN = "/")*100,2)

kable(PC,caption = "Distribution conditionnelle du sexe sachant l'état civil (%)") #5
```

Le tableau 35 nous apprend que parmi nos individus veufs, 71.3% sont des femmes. 

```{r message=FALSE,echo=FALSE}
#Profil ligne
PL =round(sweep(TDC_E, MARGIN=1,STATS = TDC_E[,5],FUN = "/")*100,2) #6

kable(PL,caption = "Distribution conditionnelle de l'état civil sachant le sexe (%)")
```

Le tableau 36 nous dit que parmi nos individus femmes, 13.21% sont célibataires.


```{r message=FALSE,echo=FALSE, warning=FALSE}
test_khi2 = chisq.test(TDC_E)
test_khi2
```

Quand on réalise le test pour savoir s'il y a indépendance entre nos deux variables, on trouve une pvaleur plutôt grande, ce qui ne nous permet pas de rejet H0, il y a indépendance entre le sexe et l'état civil.

```{r message=FALSE,echo=FALSE}
#tableau des effectifs théoriques
TET = round(test_khi2$expected,2)
kable(TET, caption = "Tableau des effectifs théoriques") #7
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
sum(  ( (TDC_E-TET)**2 ) /TET   )

ddl = 1*3
qchisq(0.95,ddl)
```

Grâce au tableau 37 on peut obtenir la statistique de notre test. On trouve 5.69 ce résultat est visible dans les sorties de notre de test. Le quantile de la loi de $\chi^2$ est de 7.81, plus grand que notre stat de test. On ne rejet donc pas l'hypothèse d'indépendance.

\newpage

### Croisement quantitatif vs qualitatif : Stress vs EtatCivil

Maintenant croisons l'état civil avec une autre variable qui est le stress.

```{r message=FALSE,echo=FALSE}
kable(t(summary(Stress)),caption = "Statistique élémentaire de la variable stress")  #8
```

Regardons les statistiques élémentaires de cette variable. Avec le tableau 8 on remarque par exemple que le stress moyen est de 18.20. 

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap= "Boite à moustache de la variable stress"}
boxplot(Stress, main= "Boite à moustache de la variable stress", col= 4, cex.main =1) #3
```

Illustrons ces statistiques. Sur la figure 9 on voit que cette variable est bien distribuée autour de la médiane. On voit également qu'il y a 2 valeurs aberrantes.

\newpage

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#Nclass sert à savoir le nombre de découpage optimal selon une méthode 
#mais ne crée pas des classes.

decoup_stress =cut(Stress,breaks = 5)
#5 classes de meme amplitude
```

```{r message=FALSE,echo=FALSE}
TDC_E_2=table(EtatCivil,decoup_stress)
kable(addmargins(TDC_E_2,FUN = sum), 
      caption = "Croisement entre l'état civil et le stress" ) #9
```

Pour analyser le croisement entre ces deux variables il faut au préalable découper en classes la variable stess. Nous la découpons en 5 classes de même amplitude. Une fois réalisé nous pouvons faire le tableau 39 du croisement des effectifs. On apprend par exemple que 58 individus mariés ont un stress entre 15 et 20.6.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
TDC_F_2=round(prop.table(TDC_E_2),3)
addmargins(TDC_F_2,FUN = sum) 
```

```{r message=FALSE,echo=FALSE}
TDC_P_2=round(prop.table(TDC_E_2)*100,3)
kable(addmargins(TDC_P_2,FUN = sum), caption = "Fréquence croisées en %" ) #10
```

Le tableau 40 nous apprend que 2.38% des célibataires ont un stress entre 9.33 et 15.

\newpage

```{r message=FALSE,echo=FALSE,out.width="60%",fig.align="center",fig.cap= "Boites à moustache du stress selon l'état civil"}
boxplot(Stress~EtatCivil,col=2:10,main="Boites à moustache du stress selon l'état civil", cex.main =1) #4
```

```{r message=FALSE,echo=FALSE,out.width="60%",fig.align="center", fig.cap= "Histograme du stress selon l'état civil"}
histogram(~Stress | EtatCivil, col = 4, main = "Histogramme du stress selon l'état civil", cex.main = 1) #5
```

On remarque avec la figure 10 et 11 que la distribution du stress entre les célibataires et les divorcés est assez similaire. Pour les mariés on retrouve une distribution étendue qui va prendre des valeurs plus grandes. Alors que pour les veufs on retrouve un étendu plus faible, les valeurs du stress pour les veufs sont plus faibles.

\newpage


```{r message=FALSE,echo=FALSE}
by(Stress,EtatCivil,summary)
```

On peut regarder les statistiques élémentaires du stress selon l'état civil. On voit par la médiane pour les veufs est plus faible que pour les autres groupes. On retrouve les mêmes résultats que la figure 10.



```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
require(BioStatR)
eta2(Stress,EtatCivil) #rapport de correlation

#7.4 % de la variabilité du stress est expliquée par l'état civil.
```

On peut calculer le rapport de corrélation entre nos deux variables. On trouve 0.075. Cela nous dit que 7.5% de la variabilité du stress est expliquée par l'état civil.


```{r message=FALSE,echo=FALSE}
#H0 : Différence non significative
#aov(Stress ~ EtatCivil)
summary(aov(Stress ~ EtatCivil))

#Pvaleur petite : rejet de H0, il y a une difference entre la valeur du stress selon les differents l'état civil.
```

On réalise un test pour savoir s'il y a une différence du stress entre les états civils. On trouve une pvaleur inférieure à 0.05, on peut rejeter l'hypothèse nul et dire qu'il y a une différence entre la valeur du stress selon les différents états civils.

\newpage

### Croisement quantitatif vs quantitatif : Age vs Satisfaction

On va maintenant voir le croisement entre les variables âge et satisfaction. 

```{r message=FALSE,echo=FALSE}
kable(t(summary(Satisfaction)), caption = "Statistiques élémentaires de la satisfaction")

```


```{r message=FALSE,echo=FALSE}
kable(t(summary(Age)), caption = "Statistiques élémentaires de l'âge")
```

Les tableaux 41 et 42 nous donnes les statistiques élémentaires sur nos variables. On remarque par exemple que la satisfaction moyenne et de 20.43 et celle de l'âge est de 41.99.


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap= "Boxplot des variable satisfaction et age"}
layout(matrix(1:2, 1), respect=TRUE)
boxplot(Satisfaction, col = 4, main ="Boxplot de la satisfaction", cex.main = 1, ylim=c(0,60))

boxplot(Age, col = 4, main ="Boxplot de l'âge", cex.main = 1, ylim=c(0,60))
#6
```

On peut rend visuel nos résultats comme dans la figure 12. On remarque que, pour les deux variables, il n'y a pas de valeur aberrante.

\newpage

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
decoup_Satisfaction = cut(Satisfaction,breaks = 5)
decoup_age = cut(Age, breaks = 4)
```

```{r message=FALSE,echo=FALSE}
TDC_E_3_1=table(decoup_Satisfaction,decoup_age)
TDC_E_3=addmargins(TDC_E_3_1,FUN = sum)
kable(TDC_E_3, caption = "Tableau de contingence entre la satisfaction et l'age") #13
```

Nous avons deux variables quantitatives. Il faut donc créer des classes pour chacune d'entre elles, afin de pouvoir les croiser. Quand on croise les effectifs, on obtient la distribution résumée dans le tableau 43. On apprend par exemple que 38 de nos individus qui ont entre 33 et 41 ans ont une satisfaction comprise ente 10.8 et 17.7. Si on est bien attentif on remarque que quand l'âge augmente, la satisfaction augmente également. Regardons cela dans un graphique.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
TDC_F_3=round(prop.table(TDC_E_3_1),3)
addmargins(TDC_F_3,FUN = sum)
```

```{r message=FALSE,echo=FALSE}
TDC_P_3=round(TDC_F_3*100,3)
TDC_P_3=addmargins(TDC_P_3,FUN = sum)
kable(TDC_P_3, caption = "Fréquence croisées entre la satisfaction et l'age (%)")
```

Avant cela, regardons d'autres façon d'illustrée le croisement entre nos deux variables. Avec le tableau 44 on retrouve le pourcentage de chaque croisement.

\newpage

```{r message=FALSE,echo=FALSE, out.width="60%",fig.align="center",fig.cap= "ballon plot de la satisfaction croisée avec l'âge"}
ggballoonplot(TDC_E_3 ,fill = "value", col =4 , main= "ballon plot de la satisfaction croisée avec l'âge", cex.main  = 1 ) #7
```

Ou encore avec la figure 13 qui donne un cercle plus ou moins gros selon l'effectif du croisement.

```{r message=FALSE,echo=FALSE,out.width="60%",fig.align="center", fig.cap= "Nuage de points de la satisfaction selon l'age"}
plot(Satisfaction~Age, pch = 20, col=4, main = "Nuage de points de la satisfaction selon l'âge") 
```

Graphiquement on se rend compte directement de la liaison entre nos deux variables. La figure 14 nous montre une relation qui est croissante est positive. On voit un point qui ne se comporte pas comme les autres, un intrus.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap= "Nuage de points de la satisfaction croisée à l'âge selon le sexe"}
scatterplot(Satisfaction~Age|Sexe,
            regLine =FALSE, grid =F,smooth = FALSE, legend = FALSE,
            main ="Nuage de points de la satisfaction croisée à l'age selon le sexe", 
            cex.main = 1,
            col=c("pink",4),pch=c(2,3))

legend("topleft",c("Femme","Homme"),cex=.8, col=c("pink",4),pch=c(2,3), text.font=4) #8
```

On peut ajouter l'information sur le sexe comme sur la figure 15. Le sexe ne semble pas avoir d'influence sur notre croisement de la satisfaction et de l'âge.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
cov_SxA = mean(Age*Satisfaction) - (mean(Age)*mean(Satisfaction))
cov_SxA
cov(Satisfaction,Age)
```


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
cov(Satisfaction,Age)/(sd(Satisfaction)*sd(Age))
cor(Satisfaction,Age)
```


```{r message=FALSE,echo=FALSE}
kable(round(cor(cbind(data[6:10],Age)),3), caption = "Matrice des corrélations") #15
```

Le tableau 45 nous donne les liens entre chaque variable. Plus le chiffre est proche de 1 plus les liens et fort positivement, plus il est proche de -1 plus le lien et fort mais négativement. Vers 0 la relation est faible. Pour la satisfaction et l'âge on voit un coefficient très proche de 1, ce qui confirme les résultats vus précédemment.

\newpage

```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center",fig.cap= "corrélogramme"}
corrplot(cor(data[6:10]), type="upper", order="hclust", 
         tl.col="black", tl.srt=45, cex.main=1) #9
```

On peut illustrer ce tableau comme le montre la figure 16. Plus le cercle est bleu plus la corrélation est forte, comme par exemple avec l'ancienneté et la satisfaction.


\newpage



# Chapitre 3 : Analyse en Composantes Principales

## Exercice 23

L'objectif va être de retrouver les données trouvées en cours sur un jeu de données. Les informations présentent dans le cours sont sur ces données : la matrice de corrélation, le vecteur propre, les valeurs propres, ainsi que les coordonnées pour les variables et individus. 

```{r message=FALSE,echo=FALSE}
Z1 = c(1.00 ,2.00, 3.00 ,4.00, 9.00)
Z2 = c(5.00 ,10.00 ,8.00 ,8.00 ,12.00)
Z =data.frame(Z1,Z2)
kable(Z,caption = "Données")  #1
```

Le tableau 46 nous montre les données utilisées, il y a 2 variables, Z1 et Z2, pour 5 individus.

```{r message=FALSE,echo=FALSE}
X1 = round((Z1 - mean(Z1)) / 2.79 , 3) #sd(Z1)
X2 = round((Z2 - mean(Z2)) / 2.33 , 3) #sd(Z2)
X =data.frame(X1,X2)
kable(X, caption = "Données centrée réduite") #2
```

Pour étudier ces données il faut d'abord les centrer et réduire. Nous obtenons donc les données du tableau 47 avec X1 et x2 comme nouvelles variables. Dans le cours les écarts types utilisés sont faux. Ici on utilisera les écarts types du cours afin d'avoir les mêmes résultats que dans le cours.

```{r message=FALSE,echo=FALSE}
#Matrice des corrélations
kable(round(cor(X),3),caption = "Matrice des corrélations" ) #3
```

La première matrice que nous avons est la matrice des corrélations. On trouve avec le tableau 48 un rapport de corrélation de 0.788 comme dans le cours. Il y a donc une légère corrélation positive entre nos deux variables.


```{r message=FALSE,echo=FALSE}
#Matrice des covariances
n= dim(X)[1]
R <-t(as.matrix(X))%*%as.matrix(X)/(n-1) #cov(X) et non cor(X) comme dit dans le cour

e <- eigen(cor(X))
#dim(e$vectors)

V <- e$vectors #Vecteur Propre 
kable(round(V,3),caption = "Vecteur Propre") #4
```

On calcule ensuite le vecteur propre, qui constitue le tableau 49. On trouve une différence par rapport aux résultats du cours. En effet le signe moins n'est pas sur la même valeur dans le cours.

\newpage

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
VP =round(e$values ,3)

VarExpA1 = VP[1]/2 *100
VarExpA2 = VP[2]/2 *100
```

Le premier facteur associé à la valeur propre 1.787, et 0.212 pour le deuxième. On va donc retrouver les mêmes valeurs de pourcentages de variance expliquées, 89.4% pour l'axe 1 et 10,6% pour l'axe 2. On conservera ces deux axes.

```{r message=FALSE,echo=FALSE}
#Coordonnée des variables
Cord_Axe1 = sqrt(VP[1])*V[,1] #Coordonée de X1 et X2 sur l'axe 1
Cord_Axe2 = sqrt(VP[2])*V[,2] #Coordonée de X1 et X2 sur l'axe 1
Cord = cbind(Cord_Axe1,Cord_Axe2)
rownames(Cord) = c("X1","X2")
kable(round(Cord,3),caption = "Coordonnées des variables") #5
```

On peut calculer les coordonnées de nos deux variables. Nous trouvons avec le tableau 50 que les coordonnées de X1 seront de 0.944 sur l'axe 1 et -0.326. Et pour X2, 0.947 sur l'axe 1 et 0.325 pour l'axe 2. Par rapport aux résultats du cours on retrouve le même problème vis-à-vis du signe moins.


```{r message=FALSE,echo=FALSE}
#Coordonnée des individus
Fbis <- as.matrix(X)%*%V
colnames(Fbis) =  c("X1","X2")
rownames(Fbis) =1:5
kable(round(Fbis,3),caption = "Coordonnées des individus") #6
```

Il nous reste plus que les coordonnées des individus. Ont les retrouvent dans le tableau 51. Les individus 1 et 5 contribuent fortement à l'axe 1, tandis que l'individu 2 contribue le plus à l'axe 2.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pr1 <- princomp(Z,cor=T)
res.pr2 <- prcomp(Z,scale=TRUE)
```

Nous allons maintenant comparer 2 fonctions qui réalisent des ACP sous R. Il s'agit de princomp et prcomp. On conservera les données précedentes.

```{r message=FALSE,echo=FALSE}
#Valeur Propre

# princomp
kable(round(get_eigenvalue(res.pr1),3), caption = "Valeurs propres avec princomp") 
kable(round(get_eigenvalue(res.pr2),3) , caption = "Valeurs propres avec prcomp") 
```

On commene par les valeurs propres. On voit les sorties des deux fonctions dans les tableaux 52 et 53, et on remarque que les sorties sont exactement les mêmes.

\newpage

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
# princomp
ind1 = get_pca_ind(res.pr1) #individus
var1 = get_pca_var(res.pr1) #variable

#prcomp
ind2 = get_pca_ind(res.pr2) #individus
var2 = get_pca_var(res.pr2) #variable
```

```{r message=FALSE,echo=FALSE}
kable(round(var1$coord,3), caption = "coordonnées des variables avec princomp") #9
kable(round(var2$coord,3) , caption = "coordonnées des variables avec prcomp") #10
# coordonnées des variables pour créer un nuage de points.
```

Pour les coordonnées des variables on voit dans les tableaux 54 et 55, les sorties des deux fonctions sont les mêmes. A noter qu'avec ces deux fonctions le signe moins est comme dans le cours. On va voir que cela est différent avec la fonction PCA.

```{r message=FALSE,echo=FALSE}
kable(round(var1$cos2,3), caption = "Cos2 des variables avec princomp")
kable(round(var2$cos2,3),caption = "Cos2 des variables avec prcomp")
# Représente la qualité de représentation des variables sur le graphique de l’ACP.
```

Pour les qualités de représentations des variables (cos2) des variables on voit dans les tableaux 10 et 11, les sorties des deux fonctions sont les mêmes.

```{r message=FALSE,echo=FALSE}
kable(round(var1$contrib,3), caption = "Contributions des variables avec princomp")
kable(round(var2$contrib,3),caption = "Contributions des variables avec prcomp")
#contient les contributions (en %), des variables, aux composantes principales
```

Et pour finir les contributions des variables sont aussi la mêmes entre les deux fonctions.

\newpage

```{r message=FALSE,echo=FALSE}
kable(round(ind1$coord,3), caption = "Coordonnées des individus avec princomp")
kable(round(ind2$coord,3),caption = "Coordonnées des individus avec prcomp")
```

Pour les individus maintenant. C'est là que l'on retrouve des différences. Déjà pour les coordonnées on trouve des dissimilarités on le voit dans les tableaux 60 et 61.

```{r message=FALSE,echo=FALSE}
kable(round(ind1$cos2,3), caption = "Cos2 des individus avec princomp")
kable(round(ind2$cos2,3),caption = "Cos2  des individus avec prcomp")
```

Cependant les qualités de représentation des individus (cos2) sont les mêmes d'une fonction à une autre.

\newpage

```{r message=FALSE,echo=FALSE}
kable(round(ind1$contrib,3), caption = "Contributions des individus avec princomp")
kable(round(ind2$contrib,3),caption = "Contributions  des individus avec prcomp")
```

Et pour les contributions, on remarque dans les tableaux ci-dessus que les valeurs sont différentes.

Les plus grosses différences entre princomp et prcomp ce font au niveau des individus et non pour les variables. Regardons maintenant les résultats avec la fonction PCA.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pca = PCA(Z, graph = F) #centre réduit automatiquement
```



```{r message=FALSE,echo=FALSE}
#Valeur Propre
kable(round(get_eigenvalue(res.pca),3), caption = "Valeurs propres avec PCA") #20
```

Pour les valeurs propres, on retrouve encore les résultats précédents comme le montre le tableau 66. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ind = get_pca_ind(res.pca) #individus
var = get_pca_var(res.pca) #variable
```

```{r message=FALSE,echo=FALSE}
kable(round(var$coord,3), caption = "coordonnées des variables avec PCA") 
```

Pour les coordonnées des variables on voit dans le tableau 67 que le signe moins est placé comme pour l'ACP à la main. Plus exactement ce signe change de position si on utilise les données centrées réduites, hors ceci est fait automatiquement dans cette fonction.

\newpage

```{r message=FALSE,echo=FALSE}
kable(round(var$cos2,3), caption = "Cos2 des variables avec PCA")
kable(round(var$contrib,3), caption = "Contributions des variables avec PCA")
```

Pour les qualités de représentation des variables et les contributions, pas de problème on retrouve les mêmes résultats avec les 3 fonctions.


```{r message=FALSE,echo=FALSE}
kable(round(ind$coord,3), caption = "Coordonnées des individus avec PCA")
```

Maintenant regardons les résultats de PCA avec les individus. Pour les coordonnées la fonction PCA s'accorde avec la fonction princomp.

```{r message=FALSE,echo=FALSE}
kable(round(ind$cos2,3), caption = "Cos2 des individus avec PCA")
```

Pour le cos2, la fonction PCA s'accorde avec toutes les autres méthodes.


```{r message=FALSE,echo=FALSE}
kable(round(ind$contrib,3), caption = "Contributions des individus avec PCA")
```

Et pour finir le tableau ci-dessus nous montre que les contributions de la fonction PCA sont les mêmes qu'avec la fonction princomp.

On en déduit que les fonctions PCA et princomp réalise l'ACP de la même façon.

\newpage 

## Exercice 24

Dans cette partie on traitera des données des stations de ski en Savoie. On dispose, pour 32 stations, des variables suivantes (données 1998).

— prixforf : prix du forfait 1 semaine (Euros)

— altmin : altitude minimum de la station (m)

— altmax : altitude maximum de la station (m)

— pistes : nombre de pistes de ski alpin

— kmfond : nombre de kilomètres de pistes de ski de fond remontee : nombre de remontées
mécaniques


```{r message=FALSE,echo=FALSE}
data=read.csv("C:/Users/ilias/OneDrive/Bureau/AD/stations.txt", sep="")
data = data[2:6]
attach(data)
kable(head(data),caption = "Extrait des données")
```

Voici un extrait des données que nous traiterons.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.pca.station = PCA(data , graph = FALSE) #centre réduit automatiquement
```


### Valeurs propres :

Les valeurs propres mesurent la quantité de variance expliquée par chaque axe principal. Nous examinons les valeurs propres pour déterminer le nombre de composantes principales à prendre en considération. 

```{r message=FALSE,echo=FALSE}
VP = round(get_eigenvalue(res.pca.station) , 3)
kable(VP, caption = "Valeurs propres")
#Extraction des valeurs propres/variances des composantes principales.
```

\newpage 

```{r message=FALSE,echo=FALSE, fig.cap= "Visualisation des valeurs propres"}
fviz_eig(res.pca.station , addlabels = TRUE)
#Visualisation des valeurs propres.
```

On voit avec le tableau 74 et la figure 17 qu'avec 3 axes on obtient une variance expliquée de presque 90%, ce qui est suffisant. On conservera donc les 3 premières dimensions. 


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ind.station = get_pca_ind(res.pca.station) #individus
var.station = get_pca_var(res.pca.station) #variable
#retourne une liste d’éléments contenant tous les résultats pour les variables ou individus actives
```

 

### Variables :

```{r message=FALSE,echo=FALSE}
CV = round(var.station$coord ,3)
kable(CV, caption = "coordonnées des variables")
# coordonnées des variables pour créer un nuage de points.
```

Le tableau suivant montre les valeurs des coordonnées afin de créer un cercle des corrélations.

\newpage 

```{r message=FALSE,echo=FALSE}
QR = round(var.station$cos2 ,3)
kable(QR, caption = "Qualité de représentation des variables ")
# Représente la qualité de représentation des variables sur le graphique de l’ACP.
```


```{r message=FALSE,echo=FALSE, fig.cap= "Corrélogramme des variables pour chaque dimension"}
#visualiser le cos2 des variables 
corrplot(var.station$cos2, is.corr=FALSE) #Corrélogramme sur toutes les dimensions
#ou 
#fviz_cos2(res.pca.station, choice = "var", axes = 1 :2) 
#diagramme en barre ici on considère l'axe 1 et 2
```

Ensuite on regarde les qualités de représentations des variables pour chaque dimension à l'aide du graphique et tableau ci-dessus. On voit par exemple que les variables prixforf et piste sont très bien représentées sur l'axe 1.

\newpage 

```{r message=FALSE,echo=FALSE}
kable(round(var.station$contrib,3), caption = "Contributions des variables")
#contient les contributions (en %), des variables, aux composantes principales
```

```{r message=FALSE,echo=FALSE, fig.cap="Diagramme en barre des contributions des variables"}
#visualiser les contribution des variables 

#corrplot(var.station$contrib, is.corr=FALSE) #chaque dimension

#ou

#Si vos données contiennent de nombreuses variables, vous pouvez décider de ne montrer que les principales variables contributives. avec les barplot.

#La ligne en pointillé rouge, sur le graphique ci-dessus, indique la contribution moyenne attendue. (1/nb_variable). une variable avec une contribution supérieure à ce seuil pourrait être considérée comme importante pour contribuer à la composante.

#fviz_contrib(res.pca.station, choice = "var", axes = 1, top = 5) 
# ici pour 10 variables sur l'axe 1

fviz_contrib(res.pca.station, choice = "var", axes = 1:2, top = 5)
# ici pour 10 variables sur l'axe 1 et 2

```

On s'intéresse maintenant à la contribution des variables. On voit avec le tableau 77 les contributions de chaque variable pour chaque dimension. Par exemple la variable prixforf contribue à 36.7% de l'axe 1. Le graphique nous montre ces contributions pour le premier plan. La ligne rouge indique la contribution moyenne attendue. Toutes les variables qui dépassent cette ligne sont considérées comme importantes pour contribuer au premier plan.

\newpage 

```{r message=FALSE,echo=FALSE,fig.cap= "Cercle de corrélation des variables"}
#Cercle de corrélation pour les variables on represente les coordonéees, la proximité d'une fleche au cercle indique le cos2
fviz_pca_var(res.pca.station, axis = c(1,2),repel = TRUE, col.var = "cos2" , gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), axes = c(1,2), alpha.var = "contrib"
             )
#paramètre :

# col.var = "cos2" : Color par rapport au cos2
# col.var = "contrib" : Color par rapport au contribution
# gradient.cols= ... : couleur qu'on veut
# repel : évite le chevauchement de texte
#alpha.var = "cos2" : transparence de la fleche selon le cos2
#alpha.var = "contrib" : transparence de la fleche selon la contribution

# col.var = ... : possible de colorer les variables par n’importe quelle variable continue personnalisée.

#On peut aussi coloré par groupe de variable qualitative ou crée des groupes si on en à pas par exemple avec enutilisant l’algorithme de classification k-means :
# res.km <- kmeans(var$coord, centers = 3, nstart = 25)
# grp <- as.factor(res.km$cluster)
# col.var = grp 

#Argument en plus :

# geom.var = "point", pour afficher uniquement les points 
#geom.var = "text" pour afficher uniquement le texte d’annotation des points
# geom.var = c("point", "text") pour afficher à la fois les points et le texte
#geom.var = c("arrow", "text") pour afficher les flèches et les annotations (par défaut).

#pointshape = ... : Forme du point (ggpubr ::show_point_shapes() pour plus de formes de points)
#labelsize : taille du texte, par exemple : labelsize = 4.
#pointsize : taille des points, par exemple : pointsize = 1.5.
#arrowsize :  Contrôle l’épaisseur des flèches, par exemple : arrowsize =0.5.

#axes.linetype = ... : utilisé pour spécifier le type de trait des axes.(toutes les valeurs possibles ggpubr ::show_line_types())
#axes.linetype = "blank" pour les supprimé
```

On peut représenter l'ensemble de ces résultats dans le cercle des corrélations, ici on s'interesse au premier plan. Pour la qualité de représentation (cos2) on a une variation de couleur selon son importance sur le premier plan. On voit que les variables prixfof et piste sont celles qui sont le mieux représenter dans ce plan. la transparence des flèches indique la contribution. Par exemple la variable kmfond n'a pas une grande contribution sur le premier plan. Les flèches des variables prixfof et piste sont très proches ce qui indique un lien fort positif entre ces deux variables. Tandis que atmin et kmfond son pratiquement opposée ce qui signifie un lien fort négatif.



### Individus :

```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$coord,3)), caption = "Extrait des coordonnées des individus")
# Coordonnées des individus
```

On s'intéresse maintenant aux individus. On commence par montrer leurs coordonnées qu'ils auront sur chaque dimension sur le tableau ci-dessus. Ici il n'y a pas l'ensemble des individus représentés.

```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$cos2,3)), caption = "Extrait des cos2 des individus")
# Qualité des individus
```



```{r,echo=FALSE,fig.cap= "Diagramme en barre des cos2 des individus"}
#bar plot de la qualité de représentation (cos2) des individus
fviz_cos2(res.pca.station, choice = "ind", axes = 1:2)
```

On regarde maintenant les qualités de représentation pour les différentes dimensions, qu'on retrouve dans le tableau. Le graphique nous illustre ces valeurs pour le premier plan, on voit que c'est l'individu 10 qui est le mieux représenter sur ce plan, suivis du 1 et du 32. Nous allons les retrouver après dans le graphique.

\newpage

```{r message=FALSE,echo=FALSE}
kable(head(round(ind.station$contrib,3)), caption = "Extrait des contributions des individus")
# Contributions des individus
```

```{r message=FALSE,echo=FALSE, fig.cap="Diagramme en barre de la contributions des individus"}
#visualiser la contribution des individus aux deux premières composantes principales
fviz_contrib(res.pca.station, choice = "ind", axes = 1:2)
```


On s'intéresse maintenant à la contribution des individus. On voit dans le tableau les contributions des individus sur les différents axes. Le graphique montre les individus qui contribuent le plus au premier plan. L'individu 24 est celui qui a la plus forte contribution sur ce plan. Tous les individus au-dessus de la ligne pointillée rouge peuvent être considérés comme importants pour contribuer au premier plan.

\newpage 

```{r message=FALSE,echo=FALSE,fig.cap= "Nuage de points des individus"}
#graphique des individus
fviz_pca_ind(res.pca.station, col.ind = "cos2", pointsize = "contrib",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07",'red',"black"), repel = TRUE)

# col.ind = "cos2" : Color par rapport au cos2
# col.ind = "contrib" : Color par rapport au contribution
# gradient.cols  : couleur qu'on veut
# pointsize = "cos2" : taille des point en fonction du cos2
#pointshape = ... : Forme du point (ggpubr ::show_point_shapes() pour plus de formes de points)
#fill = "#E7B800" : Color les cercle vide
# repel : évite le chevauchement de texte

#POUR MODIFIER LA TAILLE ET LA COULEUR DES POINTS EN FONCTION DU COS2 :
#fviz_pca_ind(res.pca, col.ind = "cos2", pointsize = "cos2",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE )

#Argument en plus :

#geom.ind = "point", pour afficher uniquement les points ;
#geom.ind = "text" pour afficher uniquement le texte d’annotation des individus
#geom.ind = c("point", "texte") pour afficher à la fois les points et le texte d’annotation (valeur par défaut)

#labelsize : taille du texte, par exemple : labelsize = 4.
#pointsize : taille des points, par exemple : pointsize = 1.5.

#axes.linetype = ... : utilisé pour spécifier le type de trait des axes.(toutes les valeurs possibles ggpubr ::show_line_types())
#axes.linetype = "blank" pour les supprimé

```

On peut maintenant tracer le nuage de points des individus sur le premier plan. Chaque point à une épaisseur proportionnelle  à sa contribution. On retrouve les individus 24, 10 et 16 qui sont les plus gros points et qui contribuent le plus. De plus nous pouvons voir une couleur plus chaude quand la qualitée de représentation (cos2) est élevée, et inversement. Les individus 10,1,24,6,22,8, et 32 sont de couleur noire qui correspond à une très bonne qualité de représentation sur ce plan. 

\newpage 

### Variables & individus :

```{r, echo=FALSE, fig.cap= "Bitplot"}
#Création d’un biplot des individus et des variables.
fviz_pca_biplot(res.pca.station,col.var = "#2E9FDF",col.ind = "#696969") 
```


Pour finir on va analyser les individus et les variables ensembles sur le premier plan, en supposant les deux graphiques précédents. Le graphique nous apprend quels sont les individus qui ont une forte valeur selon les variables. Pour la variable altmax par exemple, les individus 29, 12, 21, sont ceux qui ont une forte valeur pour cette variable. Et inversement, on peut savoir quels individus ont une faible valeur pour une variable. Les individus 27, 25, 26 par exemple sont opposés à la flèche de la variable kmfond, ceux qui indiquent une faible valeur de ces individus pour cette variable.



\newpage


# Chapitre 4 : Analyse Factorielle des Correspondances (AFC)

## Exercice 31

Nous travaillons avec le jeu de données USArrests disponible dans R. Ces données contiennent  des statistiques, en nombre d'arrestations pour 100 000 résidents pour agression, meurtre et viol dans chacun des 50 États américains en 1973. Le pourcentage de la population vivant dans des zones urbaines est également indiqué.

Murder : Nombre d'arrestations pour meurtre (pour 100 000 résidents) 

Assault : Nombre d'arrestations pour agression (pour 100 000 résidents)

UrbanPop : Pourcentage de la population urbaine

Rape : Nombre Arrestations pour viols (pour 100 000 résidents)

L'objectif va être de comparer les sorties de l'ACP sur ces données avec 3 fonctions différentes, PCA, prcomp, et princomp. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
data(USArrests)
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#PCA
res.pca = PCA(USArrests , graph = FALSE)
ind_pca = get_pca_ind(res.pca)

#prcomp
res.pca.prcomp <- prcomp(USArrests, scale = TRUE)
ind_prcomp = get_pca_ind(res.pca.prcomp)

#princomp
res.pca.princomp <- princomp(USArrests, cor = TRUE)
ind_princomp = get_pca_ind(res.pca.princomp)
```


```{r message=FALSE,echo=FALSE} 
#coordonée
kable(head(round(ind_pca$coord,3),5), caption = "Extrait des Coordonnées avec PCA")
kable(head(round(ind_prcomp$coord,3),5), caption = "Extrait des Coordonnées avec prcomp")
kable(head(round(ind_princomp$coord,3),5), caption = "Extrait des Coordonnées avec princomp")
```


On remarque que les sorties des coordonnées sont quasiment les mêmes entre PCA et princomp, il y a que sur la dimension 2 que le signe est différent. La fonction prcomp elle prend des valeurs totalement diférentes.

```{r message=FALSE,echo=FALSE}
#cos2
kable(head(round(ind_pca$cos2,3),5), caption = "Extrait des Cos2 avec PCA")
kable(head(round(ind_prcomp$cos2,3),5), caption = "Extrait des Cos2 avec prcomp")
kable(head(round(ind_princomp$cos2,3),5), caption = "Extrait des Cos2 avec princomp")
```

Pour les qualités de représentation (cos2), les 3 fonctions apportent le même résultat.


```{r message=FALSE,echo=FALSE}
#contribution 
kable(head(round(ind_pca$contrib,3),5), caption = "Extrait des Contributions avec PCA")
kable(head(round(ind_prcomp$contrib,3),5), caption = "Extrait des Contributions avec prcomp")
kable(head(round(ind_princomp$contrib,3),5), caption = "Extrait des Contributions avec princomp")
```

Et pour finir avec les contributions, les fonctions PCA et princomp ont la même sortie. tandis que prcomp propose des contributions différentes.




## Exercice 32

On considère un ensemble de 18282 individus pour lesquels on connaît la CSP, catégorie socio-professionnelle (modalités agriculteur AGRI, cadre supérieur CADR, inactif INAC, et ouvrier OUVR) et le choix de l’hébergement pour les vacances, HEB (modalités camping CAMP, HOTEL, location LOCA, et résidence secondaire RESI).

Le but sera de représenter les éventuels liens entre la CSP et le type d’hébergement choisit HEB.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#donnée 

AGRI = c( 239, 155 ,129 ,0, sum( 239, 155 ,129 ,0))
CADR = c(1003, 1556, 1821, 1521, sum(1003, 1556, 1821, 1521))
INAC = c(682, 1944 ,967, 1333, sum(682, 1944 ,967, 1333))
OUVR = c(2594, 1124, 2176 ,1038, sum(2594, 1124, 2176 ,1038))

TOTAL = c( 239+1003+682+2594 , 155+1556+1944+1124 , 129+1821+967+2176 , 1521+1333+1038, sum( 239+1003+682+2594+155+1556+1944+1124+129+1821+967+2176 +1521+1333+1038) )

data = rbind(AGRI ,CADR, INAC,OUVR, TOTAL)

colnames(data) = c("CAMP" ,"HOTEL", "LOCA" ,"RESI", "TOTAL")
```


```{r message=FALSE,echo=FALSE}
kable(data, caption = "Tableau de contingence de CSP et HEB" ) 
```

Voici le tableau de contingence que nous utiliserons pour notre analyse.

```{r message=FALSE,echo=FALSE}
chisq.test(data[1:4,1:4])
```

On commence par réaliser un test du $\chi^2$. On trouve statistique du $\chi^2$ de 2067.9, et une pvaleur associée très proche de 0. Donc on rejette l'hypothèse d'indépendance, il y a un lien à étudier entre les CSP et HEB.

\newpage

```{r message=FALSE,echo=FALSE}
#Profil ligne
PL =round(sweep(data,MARGIN=1,STATS = data[,5],FUN = "/")*100,2)
kable(PL,caption = "Tableau des distributions conditionnelles des HEB sachant la CSP (%)" )
```

On commence par les profils lignes. On apprend dans le tableau 91 que 37.42% des ouvriers choisissent le camping comme hébergement de vacance.


```{r message=FALSE,echo=FALSE}
PC =round(sweep(data,MARGIN=2,STATS = data[5,],FUN = "/")*100,2)
kable(PC,
      caption = "Tableau des distributions conditionnelles des CSP sachant HEB (%)")
```

Avec les profils colonnes, on voit que parmi ceux qui choisissent une résidence secondaire comme logement de vacance, 39.08% sont des cadres.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.ca <- CA(data[1:4,1:4], graph = FALSE)
row <- get_ca_row(res.ca)
col = get_ca_col(res.ca)
```

On réalise ensuite l'AFC de nos données. On commence par étudiant l'inertie de la variance.

```{r message=FALSE,echo=FALSE}
#valeur propre
eig.val <- get_eigenvalue (res.ca)
kable(round(eig.val,3) , caption =  "Valeur propre")
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des valeurs propres"}
fviz_screeplot (res.ca, addlabels = TRUE, ylim = c(0, 100))+ geom_hline (yintercept = 33.33, linetype = 2,color = "red")
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
18282*(sum(eig.val[,1]))
```

Voici le tableau et le graphique de nos valeurs propres. Quand on fait la somme des valeurs propres multipliées par n, on retrouve bien la statistique du $\chi^2$.

les deux premiers axes expliquent 99.9% de la variance totale. C’est quasiment la totalité. Les dimensions 1 et 2 expliquent environ 86,5% et 12.256% de l’inertie totale, respectivement. On conserve ces 2 dimensions.

On trouve ensuite les différents indicateurs et commence par les modalités de CSP.

```{r message=FALSE,echo=FALSE}
# Coordonnées
kable(round(row$coord,3), caption = "Coordonnées des modalités de CSP") 
```

Le tableau 94 nous montre les coordonnées que prendront les modalités de CSP sur les graphiques pour chaque dimension. 

\newpage

```{r message=FALSE,echo=FALSE}
# Cos2 : qualité de représentation
kable(round(row$cos2,3), caption = "Cos2 des modalités de CSP") 

#Les valeurs de cos2 sont comprises entre 0 et 1. La somme des cos2 pour les lignes sur toutes les dimensions de l’AFC estégale à 1.

#Si un point ligne est bien représenté par deux dimensions, la somme des cos2 est proche de 1. Pour certainséléments lignes, plus de 2 dimensions sont nécessaires pour représenter parfaitement les données.
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des cos2 des modalités de CSP"}
#visualier le cos2 des points lignes sur toutes les dimensions
corrplot(row$cos2, is.corr = FALSE)
```

On s'intéresse ensuite aux qualités de représentation. On remarque dans le tableau et sur le graphique, que les inactifs et les ouvriers auront une bonne représentation sur l'axe 1.


```{r message=FALSE,echo=FALSE }
# Contributions
kable(round(row$contrib,3), caption = "Contributions des modalités de CSP")
```

\newpage

```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center",fig.cap="Visualisation des contributions des modalités de CSP"}
#bar plot des contributions des lignes
fviz_contrib (res.ca, choice = "row", axes = 1 :2, top = 10)
# Contribution totale aux dimensions 1 et 2

#top = ...  : écider de ne montrer que les lignes les plus contributives
```


Regardons maintenant les contributions. Le tableau 96 nous montre le pourcentage de la contribution pour chaque axe. Avec le graphique, on peut voir que les modalités OUVR et INAC sont les plus importantes dans la définition de le premier plan. La ligne pointillée rouge correspond à la contribution moyenne.



Maintenant passons aux modalités de HEB.


```{r message=FALSE,echo=FALSE}
# Coordonnées
kable(round(col$coord,3), caption = "Coordonnées des modalités de HEB") 
```

Le tableau 97 nous montre les coordonnées que prendront les modalités de HEB sur les graphiques pour chaque dimension. 

\newpage

```{r message=FALSE,echo=FALSE}
# Cos2 : qualité de représentation
kable(round(col$cos2,3), caption = "Cos2 des modalités de HEB") 

#Les valeurs de cos2 sont comprises entre 0 et 1. La somme des cos2 pour les lignes sur toutes les dimensions de l’AFC estégale à 1.

#Si un point ligne est bien représenté par deux dimensions, la somme des cos2 est proche de 1. Pour certainséléments lignes, plus de 2 dimensions sont nécessaires pour représenter parfaitement les données.
```


```{r message=FALSE,echo=FALSE, fig.cap="Visualisation des cos2",out.width="80%",fig.align="center"}
#visualier le cos2 des points lignes sur toutes les dimensions
corrplot(col$cos2, is.corr = FALSE)
```


On s'interesse ensuite aux qualités de représentation. On remarque dans le tableau et sur le graphique, que les campings et les hôtels auront une bonne représentation sur la dimension 1.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap="Visualisation des contributions des modalités de HEB"}
# Contributions
kable(round(col$contrib,3), caption = "Contributions des modalités de HEB")
```



```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap="Visualisation des contributions des modalités de HEB"}
#bar plot des contributions des lignes
fviz_contrib (res.ca, choice = "col", axes = 1 :2, top = 10)
# Contribution totale aux dimensions 1 et 2

#top = ...  : écider de ne montrer que les lignes les plus contributives
```

Regardons maintenant les contributions. Le tableau nous montre le pourcentage de la contribution pour chaque axe. Avec le graphique, on peut voir que les modalités CAMP et HOTEL sont les plus importantes dans la définition du premier plan. La ligne pointillée rouge correspond à la contribution moyenne.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center",fig.cap="Bitplot"}
#Biplot symétrique.
fviz_ca_biplot (res.ca,repel = TRUE)

# repel = TRUE : pour éviter le chevauchement de texte

#map = "symbiplot" : Biplot symétrique. Ne conserve pas les métriques des lignes et des colonnes.
```
On peut ensuite tracer le biplot entre nos deux variables sur le premier plan. Les modalités de CSP sont représentées par des points bleus et les modalités de HEB par des triangles rouges.

Quand on s'intéresse uniquement aux modalités de CSP, on remarque les cadres et agriculteurs sont opposés, ce qui indique que leurs profils s'oppose également.

Pour les modalités de HEB, on trouve ce phénomène entre les résidences secondaires et les campings.

La forme générale est un arc de cercle il y a donc un effet de Guttman. Il y a donc un ordre de nos modalités. On retrouve des groupes, on voit que les inactifs sont liés aux hôtels, les cadres sont plus proches des résidences secondaires, et les ouvriers opteront plus pour des campings. On peut imaginer qu'il y a un lien avec le coût de ces types d'Herbergement.

## Exercice 33 

Dans cette partie, nous analyserons un tableau de contingence donnant les fréquences de 4 catégories de fumeur (en colonne) pour 5 catégories de salariés (en ligne) dans une entreprise fictive. Les catégories en ligne sont :

— SM=Senior Managers,

— JM=Junior Managers,

— SE=Senior Employees,

— JE=Junior Employees,

— SC=Secretaries.

```{r message=FALSE,echo=FALSE}
data(smoke)
kable(smoke, caption = "Tableau de contingence de nos données")
```

Voici les données smokes que nous utiliserons.

```{r message=FALSE,echo=FALSE}
data_avec_marge = addmargins(as.matrix(smoke), FUN=sum)
kable(data_avec_marge, caption = "Tableau de contingence avec marge")
```


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
c = addmargins(as.matrix(smoke), FUN=sum)[6,]
r = addmargins(as.matrix(smoke), FUN=sum)[,5]
```

On peut ajouter les distributions marginales.  


```{r message=FALSE,echo=FALSE}
F_ = round((data_avec_marge/193)*100 , 3)
kable(F_,caption = "Tableau de contingence en fréquence (%)") 
```

On peut mettre le tableau de nos données en pourcentage.

\newpage

```{r message=FALSE,echo=FALSE, warning=FALSE}
Z = chisq.test(smoke)$expected
kable(Z, caption = "Tableau des effectifs théoriques")
```

Et aussi calculer le tableau des effectifs théoriques, utiles pour le test du $\chi2$.

```{r message=FALSE,echo=FALSE}
#Profil ligne
PL =round(sweep(data_avec_marge,MARGIN=1,STATS = r,FUN = "/")*100,3)
kable(PL, caption = "Profils lignes")
```

```{r message=FALSE,echo=FALSE}
PC =round(sweep(data_avec_marge,MARGIN=2,STATS = c,FUN = "/")*100,3)
kable(PC, caption = "Profils colonnes")
```

Voici les tableaux des profils lignes et colonnes. Avec les profils lignes on voit que 28% des secretaries fument "moyennement". Avec les profils colonnes, on remarque que parmi ceux qui ne fument pas, 40.98% sont Senior Employees. 

\newpage

On réalise ensuite l'AFC sur nos données.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.ca <- CA(smoke, graph = FALSE)
row <- get_ca_row(res.ca)
col <- get_ca_col(res.ca)
```


```{r message=FALSE,echo=FALSE}
#valeur propre
eig.val <- get_eigenvalue(res.ca)
kable(round(eig.val,3) , caption = "Valeurs propres")
```


```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center",fig.cap="Visualisation des valeurs propres"}
fviz_screeplot (res.ca, addlabels = TRUE, ylim = c(0, 100))+ geom_hline (yintercept = 33.33, linetype = 2,color = "red")
```

On commence par les valeurs propres. On voit dans le tableau 106 et la figure 31 que le premier plan explique 99.5% de la variance totale. Les dimensions 1 et 2 expliquent environ 87.7% et 11.7% de l’inertie totale, respectivement. On conserve ces 2 dimensions.



```{r message=FALSE,echo=FALSE}
# Coordonnées
kable(round(row$coord,3), caption = "Coordonnées pour les catégories de salarié" ) 
```

\newpage

```{r message=FALSE,echo=FALSE}
kable(round(col$coord,3), caption = "Coordonnées pour les catégories de fumeur" ) 
```

On récupère ensuite les coordonnées pour tracer le bitplot. D'abord pour les catégories de salariés, puis pour les catégories de fumeur.


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="bitplot"}
#Biplot symétrique.
fviz_ca_biplot (res.ca,repel = TRUE)

# repel = TRUE : pour éviter le chevauchement de texte
#map = "symbiplot" : Biplot symétrique. Ne conserve pas les métriques des lignes et des colonnes.
```

Et on trace ensuite le bitplot. Les catégories de salariés sont représentées par des points bleus et les catégories de fumeur par des triangles rouges. 

On remarque qu'il n'y a pas de groupe qui se forme entre catégories d'une même variable, par contre pour les catégories de salariés on voit qu'il y a une opposition entre les secretaries et les Juniors managers, ce qui signifait que leurs profils s'opposent également.

Quand on regarde les deux variables ensembles on voit des regroupements. Par exemple on se rend compte du lien qu'il y a entre les Senior Employees et les non-fumeurs, aussi entre ce qui fume "moyennement" et les Juniors employees, et entre les gros fumeurs et les juniors managers. Nous avons réussi à bien cibler les liens qui existent entre la catégorie de salariés et les catégories de fumeur.


\newpage

## Exercice 34

Il s’agit ici de proposer une méthodologie d’analyse textuelle pour identifier les auteurs de deux fragments de texte anonymes. On connaît pour chacun de ces fragments de texte la fréquence d’apparition de certaines lettres. On suppose également que les auteurs de ces textes appartiennent à la liste suivante d’écrivains du 17ème et 18ème siècles :
Charles Darwin, René Descartes, Thomas Hobbes, Mary Shelley et Mark Twain. Ainsi, 3 échantillons de 1000 caractères de textes de ces auteurs ont été examinés. La fréquence d’apparition de 16 lettres pour chacun de ces 15 échantillons est donnée dans un tableau de contingence.

Nous réaliserons l'AFC, puis nous recommencerons avec deux textes supplémentaires ou l'auteur n'est pas spécifié. 

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
ecrivain = read.csv("C:/Users/ilias/OneDrive/Bureau/AD/ecrivain.csv", row.names=1)
```


```{r message=FALSE,echo=FALSE}
chisq.test(ecrivain[1:15])
```

On commence par voir s'il y a indépendance des données. On remarque que la pvaleur est proche de zéro, donc on rejette l'hypothèse d'indépendance. L'AFC est légitime.


```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#AFC 
res.ca <- CA (ecrivain[1:15, ], graph = FALSE)
res.ca.sup <-CA (ecrivain, row.sup = c(16,17), graph = FALSE)

row <- get_ca_row(res.ca)
col <- get_ca_col(res.ca)

row.sup <- get_ca_row(res.ca.sup)
col.sup <- get_ca_col(res.ca.sup)

eig.val <- get_eigenvalue (res.ca)
eig.val.sup <- get_eigenvalue (res.ca.sup)
```


```{r message=FALSE,echo=FALSE}
kable(round(head(eig.val),3), caption = "Tableau des valeurs propres") 
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
head(eig.val.sup)
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="bitplot"}
fviz_screeplot (res.ca, addlabels = TRUE, ylim = c(0, 50))+ geom_hline (yintercept = 33.33, linetype = 2,color = "red")
```

On commence par déterminer le nombre d'axes. Avec le graphique et le tableau on remarque 
que les quatre premiers axes expliquent 80.6% de la variance totale. C’est un pourcentage acceptable. On conservera donc 4 axes dans notre analyse. Les résultats sont assez similaires quand on ajoute les individus supplémentaires, on conservera 4 axes également.


```{r message=FALSE,echo=FALSE}
kable(head(round(row$cos2, 3)) , caption = "Extrait des cos2 des auteurs" )
kable(head(round(col$cos2, 3)) , caption   = "Extrait des cos2 des lettres" )
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des cos2 des auteurs et des lettres"}
layout(matrix(1:2,1), respect=TRUE)
corrplot(row$cos2, is.corr = FALSE) 
corrplot(col$cos2, is.corr = FALSE)
```


On s'intéresse maintenant à la qualité de représentation (cos2). On remarque avec le graphique et le tableau que les textes de Mark Twain ont la meilleure représentation sur l'axe 1. Pour les lettres, ce sont le R et W qui sont bien représenté sur l'axe 1, on peut aussi voir les contributions sur les autres axes.

```{r message=FALSE,echo=FALSE}
kable(head(round(row$contrib, 3)) , caption = "Extrait des contributions des auteurs")
```


```{r message=FALSE,echo=FALSE}
kable(head(round(col$contrib, 3)) , caption = "Extrait des contributions des lettres")
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des contributions des auteurs "}
fviz_contrib (res.ca, choice = "row", axes = 1 :2, top = 10)
```



```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des contributions des lettres"}
fviz_contrib (res.ca, choice = "col", axes = 1 :2, top = 10)
```

\newpage

On regarde maintenant les contributions sur le premier plan, avec les graphiques et les tableaux ci-dessus. On voit que les auteurs qui contribuent le plus au premier plan sont Mark Twain et Charles Darwin. Pour les lettres on voit que ce sont les lettres W,C,L,D,R qui contribuent le plus au premier plan.


```{r message=FALSE,echo=FALSE, out.width="80%",fig.align="center",fig.cap="Bitplot"}
fviz_ca_biplot (res.ca,repel = TRUE)
```


Quand on trace le bit plot, on remarque qu'il y a des groupes d'auteurs qui se forment, associer à certaines lettres. Par exemple pour Charles Darwin, on voit que les lettres B et C sont celles où il y a le plus de lien. Les auteurs René Descartes et Mary Shelley sont très liés, il semble avoir la même utilisation de lettre. Mark Twain se distingue des autres, il est lié à la lettre D et aussi le plus proche du W. Pour finir Thomas Hobbes se distingue aussi mais de façon moins prononcée, il se confond presque avec René Descartes et Mary Shelley. 

\newpage

On réalise ensuite l'AFC avec les textes supplémentaires. On trouve des contributions et des qualités de représentation très similaires aux résultats précédents.



```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
head(row.sup$cos2)
head(col.sup$cos2)
#corrplot(row.sup$cos2, is.corr = FALSE)
#corrplot(col.sup$cos2, is.corr = FALSE)
head(row.sup$contrib)
head(col.sup$contrib)

#fviz_contrib (res.ca.sup, choice = "row", axes = 1 :2, top = 10)
#fviz_contrib (res.ca.sup, choice = "col", axes = 1 :2, top = 10)
```



```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Bitplot avec les textes supplémentaire"}
fviz_ca_biplot (res.ca.sup,repel = TRUE)
```

On peut refaire un bitplot en incluant c'est deux textes. On voit que le texte un est fortement similaire à un texte de Mark Twain, alors que le texte 2 semble plus lié à un texte de Thomas Hobbes. Nous allons classifier nos textes pour voir si cela se confirme.

\newpage

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
# Matrice des distances euclidienne entre individus, qui sert a tracer le dendrogramme
d.ecrivain <- dist(row$coord[,1:4])
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
# CAH - Critère de Ward
#method = “ward.D2” correspond au vrai critère de Ward utilisant le carré de la distance
cah.ward <- hclust(d.ecrivain,method="ward.D2")
```

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Dendrogramme pour classifier nos auteur"}
#dendrogramme
plot(cah.ward, main= "Dendrogramme pour classifier nos auteurs", cex.main = 1, ylab= "", xlab= "") 
rect.hclust(cah.ward,k=4) #rectangle pour différencier les classes ici en 4 classes
```


Le dendrogramme suivant nous montre la partition en 4 classes que nous offrent nos données. Cela nous permet de confirmer les conclusions que nous avons tirée avec les bitplots. On voit qu'une classe est composé des textes de t Mark Twain avec le texte 1 qui doit aussi 
être un texte de cet auteur. 

La deuxième classe comporte les textes de Thomas Hobbes avec les textes 2 qui doit être issu de cet auteur. La troisième classe est composée de deux textes de Charles Darwin, notre classification n'a pas considéré le troisième texte de Charles Darwin dans cette classe. En effet ce texte se trouve dans la quatrième classe, avec les textes de Mary Shelley et René Descartes, qui comme nous l'avons dit ont tendance à utiliser les mêmes lettres.


\newpage 




# Chapitre 5 : Analyse Factorielle des Correspondances Multiples (AFM)

## Exercice 27

Nous traiterons des données fictives ou 27 races de chiens sont décrites avec 7 variables qualitatives.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
load(file = "C:/Users/ilias/OneDrive/Bureau/AD/chien.rda")
class(chiens)
```

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
H <-subset(chiens,select=-fonction)
```

```{r message=FALSE,echo=FALSE}
kable(head(chiens), caption = "Extrait des données chiens")
```


Voici un extrait des données, nous avons 6 variables ordinales, la taille, le	poids	, la vélocité, l'intelligence, l'affectation et l'agressivité, et une variable fonction qui détermine l'utilité des chiens, qui peut être utilité, chasse ou compagnie. Pour notre analyse nous ne conserverons que les variables ordinales.

Nous allons réaliser un AFM, avec fonction comme variable supplémentaire.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.mca = MCA(chiens, quali.sup = 7, graph = FALSE)
ind= get_mca_ind(res.mca)
var =get_mca_var(res.mca)
```


```{r message=FALSE,echo=FALSE}
#Valeurs propres
eig.val <- get_eigenvalue(res.mca)
kable(round(eig.val,3) , caption = "Valeurs propres" ) 
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des valeurs propres"}
fviz_screeplot (res.mca, addlabels = TRUE, ylim = c (0, 45))
```

On commence par les valeurs propres, on voit avec le tableau qu'à partir de 4 dimensions, plus de 70% de l'inertie totale, on conserve donc les 4 premiers axes. Avec le graphique ont voit que l'axe 1 explique 28.9%, l'axe 2 23.1%, l'axe 3 12.7% et l'axe 4 9.5%. 

```{r message=FALSE,echo=FALSE}
kable(head(round(var$coord,3)), caption = "Extrait des coordonnée des variables")
```

On se focalise d'abord sur les variables. On obtient dans le tableau ci-dessus les coordonnées afin de tracer le grapahique des variables. 


```{r message=FALSE,echo=FALSE}
kable(head(round(var$cos2,3)), caption = "Extrait des Cos2 des variables") 
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des cos2 des variables"}
corrplot(var$cos2, is.corr=FALSE)
```

On se penche ensuite sur les qualités de représentations (cos2) des variables. On voit à l'aide du graphique et du tableau qu'une grande taille aura une bonne qualité de représentation sur l'axe 1. 


```{r message=FALSE,echo=FALSE}
kable(head(round(var$contrib,3)) , caption = "Extrait des contributions des variables" )
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des contributions pour les variables"}
fviz_contrib(res.mca, choice = "var", axes = 1 :2, top = 15)
```

Pour les contributions des variables sur le premier plan. On remarque avec le graphique et le tableau qu'un faible poids à la meilleure contribution au premier plan. Sur le graphique toutes les variables au-dessus de la ligne pointillée rouge peuvent être considéré comme suffisamment contribuant au premier plan. 

On passe maintenant aux individus.


```{r message=FALSE,echo=FALSE}
kable(head(round(ind$coord,3)), caption = "Extrait des coordonnées des individus")
```

D'abord avec le tableau des coordonnées.

\newpage

```{r message=FALSE,echo=FALSE}
kable(head(round(ind$cos2,3)) , caption = "Extrait des Cos2 des individus") 
```



```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des cos2 des individus"}
corrplot(ind$cos2, is.corr=FALSE)
```

Ensuite avec les qualités de représentations des individus. On ne voit par exemple avec le graphique que les teckels et les bull-dogs ont la meilleure qualité de représentation sur la dimension 1.

\newpage

```{r message=FALSE,echo=FALSE}
kable(head(round(ind$contrib,3)) , caption = "Extrait des contributions des individus" )
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des contributions des individus"}
fviz_contrib(res.mca, choice = "ind", axes = 1 :2, top = 15)
```

Pour les contributions des individus sur le premier plan. On remarque avec le graphique les chihuahuas ont la meilleure contribution au premier plan. Tous les individus au-dessus de la ligne pointillée rouge peuvent être considéré comme suffisamment contribuant au premier plan.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Bitplot"}
fviz_mca_biplot (res.mca, repel = TRUE, ggtheme = theme_minimal ())
```


On peut enfin tracer le bitplot. Les individus sont en bleu, les variables sont en rouge
et les variables supplémentaires sont en vert foncé.

On  peut faire des liens entre les individus et les variables, tous les individus proches les uns des autres peuvent être considérés comme des profils similaires. par exemple on voit que les boxers, les labradors, les dalmatiens et les espagn_bre sont similaires avec une grande taille et une vitesse élevée.

Quand on regarde les variables supplémentaires, on voit qu'elles sont éloigner les unes des autres surtout pour les chiens de compagnie qu'on arrive bien à distinguer des deux autres. 

On va s'intéresser aux rapports de corrélations entre les variables qualitatives et les deux premières composantes principales.

```{r message=FALSE,echo=FALSE}
kable(round(var$eta2[,1:2] , 3 ) , caption = "Rapports de corrélations entre les variables qualitatives et les deux premières composantes principales" )
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visualisation des rapports de corrélation"}
plot.MCA(res.mca,choix="var",invisible=c("ind"))
```

On voit avec le tableau et le graphique que le poids est la variable la plus corrélée à l'axe 1 tandis que le poids et la plus corrélée à l'axe 2. 


On décide ensuite de rajouter des données manquantes à nos données, et nous refaisons une AFM, pour voir si elles sont prises en compte.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="bitplot"}
chiensNA <- H
chiensNA[1,1] <-NA
chiensNA[2,2] <-NA

res.mca.NA <-MCA(chiensNA,graph=FALSE)
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Bitplot avec les données manquantes"}
fviz_mca_biplot (res.mca.NA, repel = TRUE, ggtheme = theme_minimal ())
```

Quand on refait le bitplot on voit bien des points supplémentaires avec -NA en suffixe, donc les données manquantes sont prises en compte par la fonction MCA comme des individus classiques, ce qui n'est pas correct.

On veut maintenant comparer l’ACM et l’AFC dans le cas particulier de deux variables qualitatives. Nous allons réaliser l’AFC du tableau de contingence croisant les variables taille et poids, et comparer les valeurs propres.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
N <-table(H[,1:2])

res.ca.N<-CA(N,graph=FALSE)
res.mca.N<-MCA(H[,1:2],graph=FALSE)
```

```{r message=FALSE,echo=FALSE}
kable(round(get_eigenvalue(res.ca.N),3), caption = "Valeurs propre de l'AFC" )
```

```{r message=FALSE,echo=FALSE}
kable(round(get_eigenvalue(res.mca.N),3), caption = "Valeurs propre de l'AFM" )
```

\newpage

```{r message=FALSE,echo=FALSE}
#relation entre les valeurs propres des deux analyses
vpAFC <- res.ca.N$eig[,1]


c = data.frame(c(round((1+sqrt(vpAFC))/2 , 3) ,round((1-sqrt(vpAFC))/2 , 3) ))
rownames(c) = c("dim 1","dim 2","dim 4","dim 3")
colnames(c)= c( "Valeurs propres")

kable(c, caption = "Valeurs propres AFM avec l'AFC")
```

On retrouve un lien entre les valeurs propres de l'AFC et l'ACM. Quand on joue avec la racine carrée des valeurs propres de l'AFC, on arrive à retouver les valeurs propres de l'ACM. 

$\frac {1+ \sqrt{vpDim1AFC} } {2} = vp \ dim1 \ ACM$

$\frac {1+ \sqrt{vpDim2AFC} } {2} = vp \ dim2 \ ACM$

$\frac {1- \sqrt{vpDim1AFC} } {2} = vp \ dim3 \ ACM$

$\frac {1- \sqrt{vpDim2AFC} } {2} = vp \ dim4 \ ACM$

Ou $vp$ sont les valeurs propres selon la méthode et la dimension.


\newpage

## Exercice 28


Dans cette partie, nous allons présenter le package R missMDA. Il gère les données manquantes en ACP et en ACM, et de choisir le nombre de composantes par validation croisée. Nous décrirons les principales fonctionnalités de ce package, avec à chaque fois une explication de la méthode.



Overimpute : Évaluez l'ajustement de la distribution prédictive après avoir effectué une imputation multiple

estim_ncpPCA : Estime le nombre de dimensions pour l'Analyse en Composantes Principales par validation croisée

MIFAMD : Effectue des imputations multiples pour des données mixtes (continues et catégorielles) en utilisant l'analyse factorielle de données mixtes.

estim_ncpMultilevel : Estimez le nombre de dimensions pour la composante principale multiniveau (ACP multiniveau, AMC multiniveau ou analyse factorielle multiniveau de données mixtes) par validation croisée.

estim_ncpMCA : Estimer le nombre de dimensions pour l'Analyse des Correspondances Multiples par validation croisée

MIPCA : Réalise une imputation multiple avec un modèle ACP. Peut être utilisé comme étape préliminaire pour effectuer une imputation multiple dans l'ACP.

MIMCA : Effectue des imputations multiples pour des données catégorielles en utilisant l'analyse des correspondances multiples.

estim_ncpFAMD : Estime le nombre de dimensions pour l'Analyse Factorielle de Données Mixtes par validation croisée

prelim : Cette fonction effectue des opérations de regroupement et de tri sur un ensemble de données imputées à plusieurs reprises. Elle crée un objet mids qui est nécessaire à l'entrée de with.mids, qui permet d'analyser l'ensemble de données imputées à plusieurs reprises. L'ensemble de données incomplètes d'origine doit être disponible pour que nous sachions où se trouvent les données manquantes.


imputeFAMD : Imputez les valeurs manquantes d'un ensemble de données mixtes (avec des variables continues et catégorielles) en utilisant la méthode des composantes principales "analyse factorielle pour données mixtes" (FAMD). Peut être utilisé comme une étape préliminaire avant d'exécuter FAMD sur un ensemble de données incomplet.

imputeMFA : Impute un jeu de données avec des variables structurées en groupes de variables (groupes de variables continues ou catégorielles).

imputeMCA : Imputez les valeurs manquantes d'un ensemble de données catégoriques en utilisant l'analyse des correspondances multiples (ACM). Peut être utilisé comme une étape préliminaire avant d'effectuer l'ACM sur un ensemble de données incomplet.


imputeCA : Imputez les entrées manquantes d'un tableau de contingence en utilisant l'analyse des correspondances (AC). Peut être utilisé comme une étape préliminaire avant d'effectuer l'AC sur un ensemble de données incomplet.

imputePCA : Impute les valeurs manquantes d'un jeu de données avec le modèle d'analyse en composantes principales. Peut être utilisé comme une étape préliminaire avant d'effectuer une ACP sur un jeu de données complet.

imputeMultilevel : Imputez les valeurs manquantes d'un ensemble de données mixtes multi-niveaux (avec une variable qui regroupe les individus, et avec des variables continues et catégorielles) en utilisant la méthode des composantes principales "analyse factorielle multi-niveaux pour données mixtes".

plot.MIMCA : À partir des ensembles de données imputées multiples, la fonction trace des graphiques pour les individus, les catégories et les dimensions pour l'analyse des correspondances multiples (ACM).


plot.MIPCA : À partir des ensembles de données imputées multiples, la fonction trace des graphiques pour les individus, les variables et les dimensions pour l'analyse en composantes principales (ACP).


\newpage



# Projet personnel : CSP et la principale source d’information

Nous étudions la relation entre la catégorie socio-professionnelle (CSP) et la principale source d'information sur les problèmes d'environnement. Sept CSP sont étudiées : 

agriculteur (AGRI),

cadre supérieur (CSUP), 

cadre moyen (CMOY), 

employé (EMPL), 

ouvrier (OUVR), 

retraité (RETR), 

chômeur (CHOM).

Les 1283 personnes interrogées devaient indiquer leur principale source d'information sur les problèmes d'environnement, parmi les six sources suivantes : 

télévision (TEL), 

journaux (JOU), 

radio (RAD), 

livres (LIV), 

associations (ASS) ,

mairie (MAI).



```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
media = read.csv2("media.csv", row.names=1)
```

```{r message=FALSE,echo=FALSE}
kable(media, caption = "Tableau de contingence")
```

Voici le jeu de données à notre disposition pour menez notre analyse. Il s'agit d'un tableau des effectifs croisés entre les deux variables que nous étudions. On apprend par exemple que 181 ouvriers ont comme principale source d'information sur les problèmes d'environnement la télévision.

\newpage

## Indépendance 

Avant de commencer à analyser nos données on vérifie s'il y a un lien entre nos deux variables. Pour cela on réalise un test d'indépendance du $\chi^2$.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
media_sm = media[-8,-7]
```

```{r, warning=FALSE, echo=FALSE}
chisq.test(media_sm)
```

On trouve une pvaleur très proche de 0, on rejette donc l'hypothèse d'indépendance, il y a un lien entre la catégorie socio-professionnelle et la principale source d'information sur les problèmes d'environnement. Une AFC est donc légitime.


## Analyse Factorielle des Correspondances


Nous allons donc réaliser l'AFC sur nos données.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
res.ca <- CA (media_sm, graph = FALSE)
row <- get_ca_row(res.ca)
col <- get_ca_col(res.ca)
```




## Valeurs propres

On cherche d'abord combien de dimension nous allons garder pour représenter au mieux nos données. 

```{r message=FALSE,echo=FALSE}
#Les valeurs propres correspondent à la quantité d’informations retenue par chaque axe

eig.val <- get_eigenvalue (res.ca)
kable(round(eig.val,3), caption = "Valeurs propres" ) 
```

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visulation des valeurs prorpes"}
fviz_screeplot (res.ca, addlabels = TRUE, ylim = c(0, 85))+ geom_hline (yintercept = 33.33, linetype = 2,
color = "red")

#droite en pointillée rouge spécifiant la valeur propre moyenne
```


Dans le tableau on voit que les deux premiers axes expliquent 93.1% de la variance totale. C’est un pourcentage très acceptable. Avec le graphique on voit que les dimensions 1 et 2 expliquent environ 75.% et 18% de l’inertie totale, respectivement. On décide donc de retenir ces deux axes.

\newpage

## Catégories socio-professionnelle

On commence par étudier la variable CSP.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
row$coord
row$cos2
row$contrib
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visulation des contrivutions des CSP sur le premier plan"}
fviz_contrib (res.ca, choice = "row", axes = 1 :2)
# Contribution totale aux dimensions 1 et 2
```


On cherche à savoir quelle catégorie socio-professionnelle contribue le plus au premier plan. Avec le diagramme en bar ci-dessus, on voit les différentes contributions pour chaque catégorie. La ligne pointillée rouge correspond à la contribution moyenne, toutes les variables au-dessus de cette ligne peuvent être considérées comme fortement contribuent au premier plan. On retient donc les agriculteurs, la classe supérieure, les retraités, et la classe moyenne qui a la meilleure contribution au premier plan.

\newpage

```{r message=FALSE,echo=FALSE}
kable(round(row$coord[,1:2] , 3) , caption = "Coordonnées des CSP sur le premier plan")
```


Avant de représenter le nuage des CSP, on regarde les coordonnées de chaque catégorie sur le premier plan. Tous les individus avec une coordonnée négative sur la dimension 1, seront dans la partie gauche du graphique, et inversement pour les coordonnées positive. Et tous les individus avec une coordonnée négative sur la dimension 2, seront dans la partie basse du graphique, et inversement pour les coordonnées positive. Par exemple les agriculteurs seront dans la partie haute gauche du graphique.



```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Nuage des CSP sur le premier plan"}
#nuage des CSP
fviz_ca_row (res.ca,
             shape.row = 15,
             col.row = "contrib",
             gradient.cols = c ("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)
```

On peut ensuite tracer le nuage des catégories socio-professionnelles. Ici il y a une couleur selon la contribution, plus la contribution au premier plan et grande, plus la couleur sera chaude. On retrouve donc la classe moyenne avec la couleur la plus chaude car comme nous venons de le voir c'est la catégorie qui contribue le plus à ce plan. 

Ici on remarque que la classe moyenne et la classe supérieure sont regroupées, cela signifie qu'ils ont un profil similaire. À l'inverse les catégories qui s'opposent vont être corrélées négativement. Par exemple les employés et les agriculteurs ont ici des profils qui s'opposent mais cela reste léger.

\newpage

## Sources d'information

On s'intéresse maintenant à la deuxième variable de nos données.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
col$coord
col$cos2
col$contrib
```


```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Visulation des contributions des sources d'information"}
fviz_contrib(res.ca, choice = "col", axes = 1 :2)
# Contribution totale aux dimensions 1 et 2
```


On commence par les contributions sur le premier plan. On voit avec le graphique que deux sources d'information ont une contribution supérieure à la contribution moyenne. Ce sont la télévision et les livres, ce seront donc ces deux modalités qui contribueront le plus au premier plan.



```{r message=FALSE,echo=FALSE}
kable(round(col$coord[,1:2] , 3) , caption = "Coordonnées des sources d'information sur le premier plan")
```

Avant de représenter le nuage des sources d'information, on regarde les coordonnées de chaque source sur le premier plan. Tous les individus avec une coordonnée négative sur la dimension 1, seront dans la partie gauche du graphique, et inversement pour les coordonnées positive. Et tous les individus avec une coordonnée négative sur la dimension 2, seront dans la partie basse du graphique, et inversement pour les coordonnées positive. Par exemple la télévision sera dans la partie basse gauche du nuage.

\newpage

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Nuage des sources d'informations"}
fviz_ca_col (res.ca,
             shape.row = 15,
             col.col = "contrib",
             gradient.cols = c ("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

```

On peut ensuite tracer le nuage des sources d'information. Comme pour le nuage précédent,  il y a une couleur selon la contribution, plus la contribution au premier plan est grande, plus la couleur sera chaude. On retrouve donc la télévision et les livres avec les contributions les plus élevés.

Ici il n'y a pas de groupe qui se forme, donc aucune source d'information n'a un profil similaire. Il y a quelque opposition, comme la télévision et les associations, donc les profils de ses deux sources d'information s'opposent, mais cela n'est pas net.

\newpage

## CSP et sources d'information

On peut maintenant croiser les deux variables pour voir les liens et les dissimilarités.

```{r message=FALSE,echo=FALSE,out.width="80%",fig.align="center", fig.cap="Graphe superposé"}
fviz_ca_biplot (res.ca,repel = TRUE)
```

Pour cela on superpose les deux nuages. Les CSP sont représentées par des points bleus et des sources d'information par des triangles rouges.

On remarque que les modalités sont disposées en arc de cercle. Ce phénomène est connu sous le nom d'effet Guttman. Il y a donc un ordre sous-tend les modalités. On voit que la classe moyenne et la classe supérieure sont fortement liées aux livres, les employés aux journaux, les ouvriers et retraités à la télévision, les chômeurs aux radios, et les agriculteurs aux mairies.

Pour aller plus loin, on imagine avec ces résultats que le coût d'une source d'information à un impact. En effet on remarque que les sources d'information gratuite comme la télévision, la radio et la mairie, vont être associées aux catégories sociales les plus modestes. Tandis que les livres et les journaux, des sources d'information payante vont plutôt être liées aux catégories les plus aisés.

```{r,echo=FALSE, results='hide', message=FALSE,warning=FALSE}
#Factoshiny::Factoshiny(media)
```

















































